{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f533356",
   "metadata": {},
   "source": [
    "# Surface template_title validation using gridded observations from source_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a68d5a",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42759a1",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a87e968",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "stamp = nc.session_info[\"stamp\"]\n",
    "out = \".trackers/\" + stamp + \".txt\"\n",
    "if not os.path.exists(\".trackers\"):\n",
    "    os.makedirs(\".trackers\")\n",
    "# save out as empty file\n",
    "with open(out, 'w') as f:\n",
    "    f.write(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2e31fe",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# grid = pd.read_csv(\"../../matched/model_grid.csv\")\n",
    "# lon = grid.loc[:,[x for x in grid.columns if \"lon\" in x]].values\n",
    "# lon = np.unique(lon)\n",
    "# lon.sort()\n",
    "# lat = grid.loc[:,[x for x in grid.columns if \"lat\" in x]].values\n",
    "# lat = np.unique(lat)\n",
    "# lat.sort()\n",
    "# # get unique values in grid and sort them\n",
    "# lon = np.unique(lon)\n",
    "# lon.sort()\n",
    "# lon_res = lon[1] - lon[0]\n",
    "# lat_res = lat[1] - lat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165557df",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "variable = \"template_variable\" \n",
    "Variable = variable.title()\n",
    "vv_name= variable\n",
    "if vv_name == \"co2flux\":\n",
    "    vv_name = \"air-sea CO~2~ fluxes\"\n",
    "if vv_name == \"poc\":\n",
    "    vv_name = \"POC\"\n",
    "if vv_name == \"doc\":\n",
    "    vv_name = \"DOC\"\n",
    "if vv_name == \"pco2\":\n",
    "    vv_name = \"pCO2\"\n",
    "source = \"source_name\"\n",
    "domain = [x for x in glob.glob(f\"../../matched/gridded/**/**/**_{variable.lower()}*.nc\") if source in x][0].split(\"/\")[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da902dbf",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff98ba5",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# read in the dictionary of the variable matchup info\n",
    "# this is a pickle\n",
    "try:\n",
    "    with open(f\"../../matched/dicts/{domain}_{vv_name}_{source}_{variable}.pkl\", 'rb') as f:\n",
    "        vv_summary = pickle.load(f)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d20026",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "if source == \"nsbc\":\n",
    "    md(\"We used version 1.1 of the **North Sea Biogeochemical Climatology** (NSBC) to validate **sea surface template_variable**. NSBC is a monthly climatology that covers the region 47°-65°N and 15°W-15°E. The data is made up of observations over the period 1960-2014. For validation purposes we only used the level 3 data, which a gridded monthly climatology at a spatial resolution of 1/4°.  The data can be download from [NSBC](https://www.cen.uni-hamburg.de/en/icdc/data/ocean/nsbc.html).\")\n",
    "else:\n",
    "    if variable == \"poc\":\n",
    "        md(\"Model and observational POC were compared using data from the National Centre for Earth Observation (NCEO).\")\n",
    "        md(\"*Summary from NCEO*\")\n",
    "        md(\"The National Centre for Earth Observation (NCEO): Monthly global Particulate Organic Carbon (POC) dataset contains POC concentrations gridded on both sinusoidal (SIN) and geographic (GEO) grid projections at 4 km spatial resolution for 1997-2020. The POC dataset has been produced using the Ocean Colour Climate Change Initiative Remote Sensing Reflectance (Rrs) products, Version 4.2. The dataset includes the Rrs at 443 nm and 555 nm with pixel-by-pixel uncertainty estimates for each wavelength.\")\n",
    "        md(\"For more details on the algorithm and its validation, please see papers by Stramski et al. (2008) and Evers-King et al. (2017). Please note that the validation of the POC algorithm is a continuing process. To increase the accuracy of POC algorithms, further in situ POC data need to be collected with high spatial and temporal resolution.\")\n",
    "\n",
    "    if variable == \"doc\":\n",
    "        md(\"## Data Source: NCEO BICEP project DOC\")\n",
    "        md(\"Modelled DOC does not included the refactory component, which is typically 40 uM. This was added to the model data to make it comparable to the NCEO data.\")\n",
    "    \n",
    "    if source == \"ostia\":\n",
    "        md(\"Temperature was validated using the OSTIA sea surface temperature dataset. The validation was performed by comparing the modelled temperature with the OSTIA data for the same time and location. The OSTIA data was downloaded from the Copernicus Marine Environment Monitoring Service (CMEMS) catalogue. A description of the dataset is available [here](https://data.marine.copernicus.eu/product/SST_GLO_SST_L4_REP_OBSERVATIONS_010_011/description).\")\n",
    "    \n",
    "    if source == \"cobe2\":\n",
    "        md(f\"Temperature was validated using the COBE2 sea surface temperature dataset. The validation was performed by comparing the modelled temperature with the COBE2 data for the same time and location. The COBE2 data was downloaded from https://psl.noaa.gov/data/gridded/data.cobe2.html.\")\n",
    "        md(f\"Observational temperature is a monthly time series from 1850 with a spatial resolution of 1°x1°.\")\n",
    "\n",
    "md(f\"**Matchup procedure**: The model and observations were matched up as follows. First, the model dataset was cropped by a small amount to make sure cells close to the boundary were removed. The model was then regridded to the observational grid if the observational grid was coarser using nearest neighbour. Only grid cells with model and observational data were maintained.\")\n",
    "\n",
    "df_mapping = pd.read_csv(\"../../matched/mapping.csv\")\n",
    "model_variable = list(df_mapping.query(\"variable == @variable\").model_variable)[0]\n",
    "\n",
    "md_markdown(f\"The following model output was used to compare with the observational values: **{model_variable}**.\")\n",
    "\n",
    "if source == \"woa\":\n",
    "    md(\"Monthly surface data was extracted from the 2023 version of the NOAA World Ocean Atlas (WOA) dataset. The WOA dataset is a set of objectively analysed climatological fields of in situ oceanographic observations. The data is available at a spatial resolution of 1°x1°. The data can be downloaded from [NOAA](https://www.nodc.noaa.gov/OC5/woa18/).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647fa244",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "ff = glob.glob(f\"../../matched/gridded/**/**/**_{variable.lower()}_*surface.nc\")\n",
    "ff = [x for x in ff if source in x]\n",
    "if len(ff) != 1:\n",
    "    raise ValueError(\"Something is wrong with the file\")\n",
    "layer = os.path.basename(ff[0]).split(\"_\")[-1].replace(\".nc\", \"\")\n",
    "ds_model = nc.open_data(ff)\n",
    "ds_model.set_precision(\"F32\")\n",
    "ds_model.subset(variable = \"model\")\n",
    "ds_model.tmean(\"month\")\n",
    "ds_year = min(ds_model.years)\n",
    "ds_model.set_year(ds_year)\n",
    "ds_times = ds_model.times\n",
    "df_times = pd.DataFrame({\"year\":[x.year for x in ds_times]}).groupby(\"year\").size().reset_index()\n",
    "df_times.columns = [\"year\", \"count\"]\n",
    "years = list(df_times.query(\"count > 1\").year)\n",
    "ds_model.as_missing(0)\n",
    "# if variable is doc, add 40\n",
    "ds_model.run()\n",
    "ds_annual = ds_model.copy()\n",
    "ds_annual.tmean()\n",
    "# ds_annual.set_longnames({ds_annual.variables[0]: Variable})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b478825b",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "## Baseline climatologies of surface template_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bcec28",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"Climatologies of model and observational {layer} {vv_name} are shown in the figures below.\")\n",
    "# model climatology years can be derived from the vv_summary\n",
    "try:\n",
    "    clim_years = vv_summary[\"clim_years\"]\n",
    "    md(f\"The model climatology is calculated using the years **{clim_years[0]}-{clim_years[-1]}**.\") \n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45c20a2",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "ff = glob.glob(f\"../../matched/gridded/**/**/**_{variable}_*surface.nc\")\n",
    "ff = [x for x in ff if source in x]\n",
    "ds_obs = nc.open_data(ff)\n",
    "ds_obs.subset(variable = \"observation\")\n",
    "ds_obs.set_precision(\"F32\")\n",
    "ds_obs.tmean(\"month\")\n",
    "ds_obs.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e10beac",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "## fix the units and names\n",
    "\n",
    "vars = [\n",
    "        \"ammonium\",\n",
    "        \"chlorophyll\",\n",
    "        \"nitrate\",\n",
    "        \"phosphate\",\n",
    "        \"oxygen\",\n",
    "        \"silicate\",\n",
    "        \"poc\",\n",
    "        \"doc\",\n",
    "    ]\n",
    "if variable in vars:\n",
    "    # set the units of obs to match model\n",
    "    ds_obs.set_units({ds_obs.variables[0]: ds_model.contents.unit[0]})\n",
    "    if variable not in [\"poc\", \"doc\"]:\n",
    "        # set the longnames of obs to match model\n",
    "        ds_obs.set_longnames({ds_obs.variables[0]: f\"Observed surface {vv_name} concentration\"})\n",
    "        ds_model.set_longnames({ds_model.variables[0]: f\"Modelled surface {vv_name} concentration\"})\n",
    "        ds_annual.set_longnames({ds_annual.variables[0]: f\"Modelled annual mean surface {variable} concentration\"})\n",
    "    else:\n",
    "        ds_obs.set_longnames({ds_obs.variables[0]: f\"Observed surface {variable.upper()} concentration\"})\n",
    "        ds_model.set_longnames({ds_model.variables[0]: f\"Modelled surface {variable.upper()} concentration\"})\n",
    "        ds_annual.set_longnames({ds_annual.variables[0]: f\"Modelled annual mean surface {variable.upper()} concentration\"})\n",
    "if variable == \"temperature\":\n",
    "    ds_obs.set_longnames({ds_obs.variables[0]: \"Observed SST\"})\n",
    "    ds_model.set_longnames({ds_model.variables[0]: \"Modelled SST\"})\n",
    "    ds_annual.set_longnames({ds_annual.variables[0]: \"Modelled SST\"})\n",
    "\n",
    "ds_obs.run()\n",
    "ds_model.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6308613",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b885730",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa9db9d",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"## Can the model reproduce seasonality of {layer} {vv_name}?\")\n",
    "\n",
    "md(f\"The ability of the model to reproduce seasonality of {layer} {vv_name} was assessed by comparing the modelled and observed seasonal cycle of {vv_name}. First, we derive a monthly climatology for the model data. Then, we calculate the Pearson correlation coefficient between the modelled and observed {vv_name} at each grid cell.\")\n",
    "\n",
    "\n",
    "md(\"Note: we are only assessing the ability of the model to reproduce the ability of the model to reproduce seasonal changes, not long-term trends.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4893bf1",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528d3c68",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    md(f\"## Regional assessment of model performance for {layer} {vv_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a330779f",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    md(\"We assessed the regional performance of the model by comparing the model with observations in a number of regions. The regions considered are mapped below.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d37725",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    lon_name = [x for x in ds_regions.to_xarray().coords if \"lon\" in x][0]\n",
    "    lat_name = [x for x in ds_regions.to_xarray().coords if \"lat\" in x][0]\n",
    "    df_mapped = (\n",
    "        ds_regions\n",
    "        .to_dataframe()\n",
    "        .reset_index()\n",
    "        # rename the columns\n",
    "        .rename(columns = {lon_name: \"lon\", lat_name: \"lat\"})\n",
    "        .melt(id_vars = [\"lon\", \"lat\"])\n",
    "        .dropna()\n",
    "        .merge(regions_contents.loc[:,[\"variable\", \"long_name\"]])\n",
    "        .drop(columns = [ \"value\"])\n",
    "    )\n",
    "    bad = [\"Rosa\", \"Locate Shelf\"]\n",
    "    df_mapped = df_mapped.query(\"long_name not in @bad\")\n",
    "    xlim = np.array([df_mapped.lon.min(), df_mapped.lon.max()])\n",
    "    ylim = np.array([df_mapped.lat.min(), df_mapped.lat.max()])\n",
    "\n",
    "    def fix_name(x):\n",
    "        x = x.replace(\"North East\", \"NE\")\n",
    "        x = x.replace(\"North \", \"N \")\n",
    "        if x == \"Channel\":\n",
    "            x = \"English Channel\"\n",
    "        return x\n",
    "\n",
    "    fix_name = np.vectorize(fix_name)\n",
    "\n",
    "\n",
    "    df_mapped.long_name = fix_name(df_mapped.long_name)\n",
    "\n",
    "else:\n",
    "    df_mapped = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c28508",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    df_all = []\n",
    "    df_summary = []\n",
    "    for vv in ds_regions.variables:\n",
    "        ds_rr = ds_regions.copy()\n",
    "        ds_rr.subset(variable = vv)\n",
    "        ds_rr.run()\n",
    "        ds_vv = ds_ts.copy()\n",
    "        time_name = [x for x in list(ds_vv.to_xarray().coords) if \"time\" in x][0]\n",
    "        ds_vv * ds_rr\n",
    "        ds_region = ds_vv.copy()\n",
    "        ds_cor = ds_vv.copy()\n",
    "        ds_cor.tmean()\n",
    "        ds_cor.cor_space(\"model\", \"observation\")\n",
    "        region = list(regions_contents.query(\"variable == @vv\").long_name)[0]\n",
    "        df1 = (\n",
    "            ds_cor\n",
    "            .to_dataframe()\n",
    "            .reset_index()\n",
    "            .loc[:,[\"cor\"]]\n",
    "            .rename(columns = {\"cor\": \"Spatial correlation\"})\n",
    "            .assign(region = region)\n",
    "        )\n",
    "        # now do the temporal correlation\n",
    "\n",
    "        ds_cor = ds_vv.copy()\n",
    "        ds_cor.cor_time(\"model\", \"observation\")\n",
    "        ds_cor.spatial_mean()\n",
    "        df2 = (\n",
    "            ds_cor\n",
    "            .to_dataframe()\n",
    "            .reset_index()\n",
    "            .loc[:,[\"cor\"]]\n",
    "            .rename(columns = {\"cor\": \"Temporal correlation\"})\n",
    "            .assign(region = region)\n",
    "        )\n",
    "        df = df1.merge(df2)\n",
    "\n",
    "        ds_vv.spatial_mean()\n",
    "        df_bias = (\n",
    "            ds_vv\n",
    "            .to_dataframe()\n",
    "            .reset_index()\n",
    "            .rename(columns = {time_name: \"time\"})\n",
    "            .loc[:,[\"time\", \"model\", \"observation\"]]\n",
    "            .assign(month = lambda x: x.time.dt.month)\n",
    "            .assign(bias = lambda x: x.model - x.observation)\n",
    "            .assign(region = region)\n",
    "            .groupby(\"region\")\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .loc[:,[\"region\", \"bias\"]]\n",
    "        )\n",
    "\n",
    "        # now add the RMSD, calculated in the same way as the bias\n",
    "        df_rmsd = (\n",
    "            ds_region\n",
    "            .to_dataframe()\n",
    "            .reset_index()\n",
    "            .rename(columns = {time_name: \"time\"})\n",
    "            .loc[:,[\"time\", \"model\", \"observation\"]]\n",
    "            .assign(month = lambda x: x.time.dt.month)\n",
    "            .assign(rmsd = lambda x: (x.model - x.observation)**2)\n",
    "            .assign(region = region)\n",
    "            .groupby(\"region\")\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .loc[:,[\"region\", \"rmsd\"]]\n",
    "            .assign(rmsd = lambda x: np.sqrt(x.rmsd))\n",
    "        )\n",
    "\n",
    "        df = df1.merge(df2).merge(df_bias).merge(df_rmsd)\n",
    "        df_summary.append(df)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        df_vv = (\n",
    "            ds_vv\n",
    "            .to_dataframe()\n",
    "            .reset_index()\n",
    "            .rename(columns = {time_name: \"time\"})\n",
    "            .loc[:,[\"time\", \"model\", \"observation\"]]\n",
    "            .melt(\"time\")\n",
    "            .assign(month = lambda x: x.time.dt.month)\n",
    "            .assign(region = vv)\n",
    "        )\n",
    "        df_all.append(df_vv)\n",
    "        ds_region.tmean()\n",
    "        df_region = (\n",
    "            ds_region\n",
    "            .to_dataframe()\n",
    "            .dropna()\n",
    "            .reset_index()\n",
    "            .loc[:,[\"model\", \"observation\"]]\n",
    "            .drop_duplicates()\n",
    "        )\n",
    "    \n",
    "        del ds_rr, ds_vv, ds_region\n",
    "    df_all = pd.concat(df_all).dropna()\n",
    "        \n",
    "    df_all = (\n",
    "        df_all\n",
    "        .merge(df_mapped.loc[:,[\"long_name\", \"variable\"]].drop_duplicates().rename(columns = {\"variable\": \"region\"}))\n",
    "    )\n",
    "    df_summary= pd.concat(df_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d062b1f0",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# restrict df_mapped to regions in df_all\n",
    "if regional:\n",
    "    regions = set(df_all.query(\"value > 0\").region)\n",
    "    df_mapped = df_mapped.query(\"variable in @regions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3287fa8",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%%R -i regional -i df_mapped -i xlim -i ylim -i global_grid\n",
    "\n",
    "if (regional){\n",
    "\n",
    "    library(tidyverse)\n",
    "\n",
    "    world_map <- map_data(\"world\")\n",
    "\n",
    "    gg <-  ggplot(df_mapped)+\n",
    "        geom_tile(aes(x = lon, y = lat))+\n",
    "        coord_cartesian(xlim = xlim, ylim = ylim)+\n",
    "        theme_bw(base_size = 10)+\n",
    "        facet_wrap(~long_name)+\n",
    "        theme(axis.title.x = element_blank(),\n",
    "              axis.title.y = element_blank())\n",
    "\n",
    "y_labels <-  as.numeric(na.omit(layer_scales(gg)$y$break_positions()))\n",
    "x_labels <- as.numeric(na.omit(layer_scales(gg)$x$break_positions()))\n",
    "x_breaks <- x_labels\n",
    "y_breaks <- y_labels\n",
    "\n",
    "# y labels are north-south coordinates. Make them more appropriate\n",
    "# i.e. 10 should be 10 °N, -10 should be 10 °S\n",
    "\n",
    "y_labels <- ifelse(y_labels >= 0, paste0(y_labels, \"°N\"), paste0(abs(y_labels), \"°S\"))\n",
    "x_labels <- ifelse(x_labels >= 0, paste0(x_labels, \"°E\"), paste0(abs(x_labels), \"°W\"))\n",
    "\n",
    "gg <- gg + scale_y_continuous(breaks = y_breaks, labels = y_labels)+\n",
    "    scale_x_continuous(breaks = x_breaks, labels = x_labels)+\n",
    "        geom_polygon(data = world_map, aes(x = long, y = lat, group = group), fill = \"grey\", color = \"grey\")\n",
    "\n",
    "\n",
    "\n",
    "    gg\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebc67b9",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    md(f\"**Figure {chapter}{i_figure}**: Regions used for validation of {layer} {vv_name}.\")\n",
    "i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec3e2e8",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    md(f\"Time series were constructed comparing the monthly mean of the spatial average {layer} {vv_name} in each region. The spatial average was calculated using the mean of all grid cells within each region, accounting for grid cell area.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e077b12",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    out_ts = f\"../../results/regionals/{source}_{variable}_regionals.csv\"\n",
    "    # check if directory exists for out_ts\n",
    "    if not os.path.exists(\"../../results/regionals\"):\n",
    "        os.makedirs(\"../../results/regionals\")\n",
    "    df_all.to_csv(out_ts, index = False)\n",
    "if not regional:\n",
    "    df_all = False\n",
    "\n",
    "if regional:\n",
    "    units = ds_ts.contents.unit[0]\n",
    "else:\n",
    "    units = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d205e",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%%R -i df_all -i regional -i variable -i units \n",
    "\n",
    "# do a seasonal plot\n",
    "if(regional){\n",
    "\n",
    "    x_lab = str_glue(\"Spatial average {variable} ({units})\")\n",
    "    x_lab <- str_replace(x_lab, \"/m\\\\^3\", \"m<sup>-3</sup>\")\n",
    "\n",
    "    library(tidyverse)\n",
    "    library(ggplot2)\n",
    "    library(ggridges)\n",
    "    library(ggthemes)\n",
    "    # make variable title\n",
    "    df_all = df_all %>%\n",
    "        mutate(variable = str_to_title(variable))\n",
    "\n",
    "    gg <- ggplot(df_all)+\n",
    "        geom_line(aes(x = month, y = value, colour = variable))+\n",
    "        facet_wrap(~long_name)+\n",
    "        labs(y = x_lab)+\n",
    "        labs(x = \"Month\")+\n",
    "        theme(legend_position = \"top\")+\n",
    "        scale_color_manual(values = c(\"red\", \"blue\"))+\n",
    "        scale_x_continuous(breaks = c(1, 4, 7, 10), labels = c(\"Jan\", \"Apr\", \"Jul\", \"Oct\"))+ \n",
    "        theme_bw(base_size = 10)+\n",
    "        labs(colour = \"\")+\n",
    "        theme(legend.position = \"top\")+\n",
    "        theme(axis.title.y = ggtext::element_markdown())+\n",
    "        scale_color_fivethirtyeight()\n",
    "\n",
    "        gg\n",
    "\n",
    "\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db278d68",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    md(f\"**Figure {chapter}{i_figure}**: Seasonal cycle of {layer} {vv_name} for model and observations for each region. The spatial average is taken over the region.\") \n",
    "    i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5437cd5",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    md(f\"The table below shows the average bias of surface {vv_name} in each region. The bias is calculated as the modelled value minus the observed value. A positive bias indicates that the model overestimates the observed value, while a negative bias indicates that the model underestimates the observed value.\")\n",
    "\n",
    "if regional:\n",
    "    # output and hide index\n",
    "    # first average things and tidy\n",
    "    df_summary = (\n",
    "        df_summary\n",
    "        # .loc[:,[\"region\", \"bias\"]]\n",
    "        .groupby(\"region\")\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        # capitalize the columns\n",
    "        .rename(columns = {\"region\": \"Region\", \"bias\": \"Bias\", \"rmsd\": \"RMSD\"})\n",
    "    )\n",
    "    # remove na values\n",
    "    df_summary = df_summary.dropna().reset_index(drop = True)\n",
    "    if not global_grid:\n",
    "        # drop the spatial correlation\n",
    "        df_summary = df_summary.drop(columns = [\"Spatial correlation\"])\n",
    "    df_display(df_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b95f9fa",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    regional_summary = [f\"**Table {chapter}{i_table}**: Summary of performance of the model surface {vv_name} in each region.\"]\n",
    "    regional_summary.append(\"The bias column represents the spatial average of the annual mean modelled value minus the observed value.\")\n",
    "    regional_summary.append(\"The temporal correlation column represents the spatial mean of the temporal correlation between the model and observations per grid cell.\") \n",
    "    if global_grid:\n",
    "        regional_summary.append(\"The spatial correlation column represents the spatial correlation between the model and observations.\")\n",
    "    regional_summary = \" \".join(regional_summary).replace(\"  \", \" \")\n",
    "    md(regional_summary)\n",
    "    i_table = i_table + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a92e0c",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7394e52e",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"## Can the model reproduce spatial patterns of {layer} {vv_name}?\")\n",
    "\n",
    "md(f\"The ability of the model to reproduce spatial patterns of {layer} {vv_name} was assessed by comparing the modelled and observed {vv_name} at each grid cell. We calculated the Pearson correlation coefficient between the modelled and observed {vv_name} at each grid cell.\")\n",
    "md(\"This was carried out monthly and using the annual mean in each grid cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acf4cb7",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "ff = glob.glob(f\"../../matched/gridded/**/**/**_{variable}*surface.nc\")\n",
    "ff = [x for x in ff if source in x]\n",
    "if len(ff) != 1:\n",
    "    raise ValueError(\"Something is wrong with the file\")\n",
    "layer = os.path.basename(ff[0]).split(\"_\")[-1].replace(\".nc\", \"\")\n",
    "ds_cor = nc.open_data(ff)\n",
    "ds_cor.set_precision(\"F32\")\n",
    "ds_cor.tmean(\"month\")\n",
    "ds_cor.cor_space(\"model\", \"observation\")\n",
    "ds_cor_df = ds_cor.to_dataframe().reset_index()\n",
    "ds_cor_df = ds_cor_df.dropna()\n",
    "time_name = [x for x in list(ds_cor.to_xarray().coords) if \"time\" in x][0]\n",
    "# rename time in dataframe\n",
    "ds_cor_df.rename(columns = {time_name: \"time\"}, inplace = True)\n",
    "# extract the month\n",
    "ds_cor_df[\"month\"] = ds_cor_df.time.dt.month\n",
    "ds_cor_df = ds_cor_df.loc[:,[\"month\", \"cor\"]].drop_duplicates()\n",
    "# change month number to month name\n",
    "ds_cor_df[\"month\"] = ds_cor_df[\"month\"].apply(lambda x: calendar.month_abbr[x])\n",
    "# now do this annually\n",
    "ds_cor = nc.open_data(ff)\n",
    "ds_cor.set_precision(\"F32\")\n",
    "ds_cor.tmean(\"month\")\n",
    "ds_cor.tmean()\n",
    "ds_cor.cor_space(\"model\", \"observation\")\n",
    "ds_cor_df_annual = ds_cor.to_dataframe().reset_index()\n",
    "ds_cor_df_annual = ds_cor_df_annual.dropna()\n",
    "time_name = [x for x in list(ds_cor.to_xarray().coords) if \"time\" in x][0]\n",
    "# rename time in dataframe\n",
    "ds_cor_df_annual.rename(columns = {time_name: \"time\"}, inplace = True)\n",
    "# extract the month\n",
    "ds_cor_df_annual[\"month\"] = ds_cor_df_annual.time.dt.month\n",
    "ds_cor_df_annual = ds_cor_df_annual.loc[:,[\"month\", \"cor\"]].drop_duplicates()\n",
    "# output to csv\n",
    "ds_cor_df_annual = ds_cor_df_annual.assign(month = \"Annual mean\")\n",
    "# merge the two dataframes\n",
    "ds_cor_df = pd.concat([ds_cor_df_annual, ds_cor_df])\n",
    "# change month to period\n",
    "ds_cor_df.rename(columns = {\"month\": \"period\"}, inplace = True)\n",
    "# Give the columns more sensible names\n",
    "ds_cor_df.rename(columns = {\"cor\": \"Correlation coefficient\"}, inplace = True)\n",
    "ds_cor_df.rename(columns = {\"period\": \"Time period\"}, inplace = True)\n",
    "# drop any na\n",
    "ds_cor_df.dropna(inplace = True)\n",
    "df_display(ds_cor_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c398f",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"**Table {chapter}{i_table}**: Pearson correlation coefficient between modelled and observed {layer} {vv_name} at each grid cell. The correlation was calculated monthly and using the annual mean in each grid cell.\")\n",
    "i_table += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aadd669",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad92f531",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if nws == False:\n",
    "    if global_grid:\n",
    "        md(f\"## Hovmöller diagram of {layer} {vv_name} for the Atlantic and Pacific Oceans\")\n",
    "    else:\n",
    "        if source == \"woa\":\n",
    "            md(f\"## Hovmöller diagram of {layer} {vv_name} for the full domain\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fae153",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "hov_plot = False\n",
    "df_hovs = False\n",
    "if global_grid or source == \"woa\" and nws == False:\n",
    "    # find the vertical paths\n",
    "    paths = glob.glob(f\"../../matched/gridded/**/**/**_{variable}*surface.nc\")\n",
    "    paths = [x for x in paths if source in x]\n",
    "    df_hovs = []\n",
    "    if len(paths) == 1:\n",
    "        for rr in [\"atlantic\", \"pacific\"]:\n",
    "            ds = ds_model.copy() \n",
    "            ds.append(ds_obs)\n",
    "            ds.merge(\"variables\", \"month\")\n",
    "            if global_grid:\n",
    "                ds_rr = ds_regions.copy()\n",
    "                ds_rr.subset(variable = rr)\n",
    "                ds.regrid(ds_rr)\n",
    "                ds * ds_rr\n",
    "            ds.zonal_mean()\n",
    "\n",
    "            lat_name = [x for x in list(ds.to_xarray().coords) if \"lat\" in x][0]\n",
    "            time_name = [x for x in list(ds.to_xarray().coords) if \"time\" in x][0]\n",
    "            rr_region = rr\n",
    "            if not global_grid:\n",
    "                rr_region = \"Full domain\"\n",
    "            df = (\n",
    "                ds\n",
    "                .to_dataframe()\n",
    "                .dropna()\n",
    "                .reset_index()\n",
    "                .loc[:,[lat_name, time_name, \"model\", \"observation\"]]\n",
    "                .rename(columns = {lat_name: \"lat\", time_name: \"time\"})\n",
    "                # get the month\n",
    "                .assign(month = lambda x: x.time.dt.month)\n",
    "                # drop time\n",
    "                .drop(columns = \"time\")\n",
    "                .assign(region = rr_region) \n",
    "\n",
    "            )\n",
    "            df_hovs.append(df)\n",
    "            if not global_grid:\n",
    "                break\n",
    "        df_hovs = pd.concat(df_hovs)\n",
    "        hov_plot = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25df5c12",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%R -i df_hovs -i vv_name -i model_unit -i global_grid -i source -i hov_plot -w 800  -h 600 \n",
    "if(hov_plot){\n",
    "library(tidyverse)\n",
    "# hovmoller plot\n",
    "\n",
    "df_hovs <- df_hovs %>%\n",
    "    gather(\"variable\", \"value\", \"model\", \"observation\") %>%\n",
    "    mutate(variable = ifelse(variable == \"model\", \"Model\", \"Observation\"))\n",
    "\n",
    "if (vv_name != \"Temperature\")\n",
    "    vv_name <- paste(vv_name, \"concentration\", sep = \" \")\n",
    "vv_name <- str_to_title(vv_name)\n",
    "# add model_unit in brackets\n",
    "vv_name <- paste(vv_name, \"(\", model_unit, \")\", sep = \"\")\n",
    "\n",
    "gg <- df_hovs %>%\n",
    "    # turn region into title\n",
    "    mutate(region = str_to_title(region)) %>%\n",
    "    ggplot(aes(x = month, y = lat, fill = value))+\n",
    "    geom_tile()+\n",
    "    theme_bw(base_size = 18)+\n",
    "    facet_grid(region~variable)+\n",
    "    # do month as J F M etc. Only first letter of month\n",
    "    scale_x_continuous(breaks = 1:12, labels = month.abb, expand = c(0, 0))+\n",
    "    theme(\n",
    "    legend.position = \"bottom\", legend.direction = \"horizontal\", legend.box = \"horizontal\", legend.key.width = unit(2.0, \"cm\"),\n",
    "    legend.key.height = unit(0.3, \"cm\"))+\n",
    "    scale_fill_viridis_c(na.value = \"white\",\n",
    "                       #breaks = c(0.4, 0.6, 0.8, 1.0), labels = c(\"0.4\", \"0.6\", \"0.8\", \">1\"),\n",
    "                       guide = guide_colorbar(title.position = \"bottom\", title.hjust = 0.5, title.theme = element_text(angle = 0, size = 16 , family = \"Helvetica\"))\n",
    "  )+\n",
    "    labs(fill = vv_name)+\n",
    "    # remove x and y labs\n",
    "    theme(axis.title.x = element_blank(),\n",
    "            axis.title.y = element_blank())\n",
    "y_labels <-  as.numeric(na.omit(layer_scales(gg)$y$break_positions()))\n",
    "y_breaks <- y_labels\n",
    "\n",
    "y_labels <- ifelse(y_labels >= 0, paste0(y_labels, \"°N\"), paste0(abs(y_labels), \"°S\"))\n",
    "\n",
    "gg <- gg +\n",
    "    scale_y_continuous(breaks = y_breaks, labels = y_labels)\n",
    "gg\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea5a4e7",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if nws == False:\n",
    "    if global_grid:\n",
    "        md(f\"**Figure {chapter}{i_figure}**: Hovmöller diagram of {layer} {vv_name} for the Atlantic and Pacific Oceans. The diagram shows the zonal mean of {vv_name} concentration for the model and observations.\")\n",
    "        i_figure += 1\n",
    "    else:\n",
    "        if source == \"woa\":\n",
    "            md(f\"**Figure {chapter}{i_figure}**: Hovmöller diagram of {layer} {vv_name} for the full domain. The diagram shows the zonal mean of {vv_name} concentration for the model and observations.\") \n",
    "            i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145be8dd",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if nws == False:\n",
    "    if global_grid:\n",
    "        md(f\"## Can the model reproduce spatial and vertical patterns in {vv_name}?\")\n",
    "        md(f\"The ability of the model to reproduce broadscale patterns in the vertical distribution of {vv_name} was assessed by comparing the zonal averages in the model and WOA23 data set for the Atlantic, Pacific, and Indian Oceans. The zonal averages were calculated using the annual average.\") \n",
    "        md(f\"Figure {chapter}{i_figure} shows the zonal averages.\") \n",
    "    else:\n",
    "        if source == \"woa\":\n",
    "            md(f\"## Can the model reproduce spatial and vertical patterns in {vv_name}?\")\n",
    "            md(f\"The ability of the model to reproduce broadscale patterns in the vertical distribution of {vv_name} was assessed by comparing the zonal averages in the model and WOA23 data set for the full domain. The zonal averages were calculated using the annual average.\") \n",
    "            md(f\"Figure {chapter}{i_figure} shows the zonal averages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbe09ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad59d26",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "zonal_plot = False\n",
    "if global_grid or source == \"woa\":\n",
    "    # find the vertical paths\n",
    "    paths = glob.glob(f\"../../matched/gridded/**/**/**_{variable}*vertical.nc\")\n",
    "    paths = [x for x in paths if source in x]\n",
    "    df_zonals = []\n",
    "    if len(paths) == 1:\n",
    "        for rr in [\"atlantic\", \"pacific\"]:\n",
    "            ds = nc.open_data(paths)\n",
    "            if global_grid:\n",
    "                ds_rr = ds_regions.copy()\n",
    "                ds_rr.subset(variable = rr)\n",
    "                ds.regrid(ds_rr)\n",
    "                ds * ds_rr\n",
    "            ds.tmean(\"year\")\n",
    "            ds.zonal_mean()\n",
    "\n",
    "            df1 = (\n",
    "                ds.to_xarray()[\"model\"]\n",
    "                .to_dataframe()\n",
    "                .reset_index()\n",
    "                .dropna()\n",
    "            )\n",
    "            depth_name = [x for x in  ds.to_xarray()[\"model\"].coords if \"depth\" in x][0]\n",
    "            lon_name = [x for x in  ds.to_xarray()[\"model\"].coords if \"lon\" in x][0]\n",
    "            lat_name = [x for x in  ds.to_xarray()[\"model\"].coords if \"lat\" in x][0]\n",
    "            #     .drop_duplicates()\n",
    "            #     # change lat_name to lat\n",
    "            #     .rename(columns = {lat_name: \"lat\"})\n",
    "            #     # change depth_name to depth\n",
    "            #     .rename(columns = {depth_name: \"depth\"})\n",
    "            #     # melt model and observation\n",
    "            #     .melt(id_vars = [\"lat\", \"depth\"])\n",
    "            #     .assign(region = rr.title())\n",
    "            # )\n",
    "            df1 = (\n",
    "                df1\n",
    "                .loc[:,[lat_name, depth_name, \"model\"]]\n",
    "                .rename(columns = {lat_name: \"lat\", depth_name: \"depth\"})\n",
    "                #.assign(region = rr.title())\n",
    "            )\n",
    "\n",
    "            df2 = (\n",
    "                ds.to_xarray()[\"observation\"]\n",
    "                .to_dataframe()\n",
    "                .reset_index()\n",
    "                .dropna()\n",
    "            )\n",
    "\n",
    "            depth_name = [x for x in  ds.to_xarray()[\"observation\"].coords if \"depth\" in x][0]\n",
    "            lon_name = [x for x in  ds.to_xarray()[\"observation\"].coords if \"lon\" in x][0]\n",
    "            lat_name = [x for x in  ds.to_xarray()[\"observation\"].coords if \"lat\" in x][0]\n",
    "            rr_region = rr\n",
    "            if not global_grid:\n",
    "                rr_region = \"full domain\"\n",
    "\n",
    "            df2 = (\n",
    "                df2\n",
    "                .loc[:,[lat_name, depth_name, \"observation\"]]\n",
    "                .rename(columns = {lat_name: \"lat\", depth_name: \"depth\"})\n",
    "            #    .assign(region = rr.title())\n",
    "            )\n",
    "            df = df1.merge(df2) \n",
    "            df = (\n",
    "                df\n",
    "                .melt(id_vars = [\"lat\", \"depth\"])\n",
    "                .assign(region = rr_region.title())\n",
    "            )\n",
    "            \n",
    "              #  .loc[:,[lat_name, depth_name, \"model\", \"observation\"]]\n",
    "            df_zonals.append(df)\n",
    "            if not global_grid:\n",
    "                break\n",
    "        df_zonals = pd.concat(df_zonals)\n",
    "        # output to adhoc folder\n",
    "        out_file = \"adhoc/df_zonals.feather\"\n",
    "        # create folder if it doesn't exist\n",
    "        if not os.path.exists(\"adhoc\"):\n",
    "            os.makedirs(\"adhoc\")\n",
    "        df_zonals.to_feather(out_file)\n",
    "        zonal_plot = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b368fa57",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%R -i global_grid -i model_unit -i vv_name -i source -i zonal_plot\n",
    "library(tidyverse)\n",
    "if (zonal_plot){\n",
    "    df_zonals <- arrow::read_feather(\"adhoc/df_zonals.feather\")\n",
    "df_zonals <- df_zonals %>%\n",
    "    mutate(depth = -depth) %>%\n",
    "    mutate(depth = depth / 1000) %>%\n",
    "    arrange(desc(depth)) %>%\n",
    "    group_by(region,lat, variable) %>%\n",
    "    mutate(lag = lag(depth)) %>%\n",
    "    replace_na(list(lag = 0)) %>%\n",
    "    mutate(width = depth - lag)\n",
    "\n",
    "# make vv_name a title\n",
    "# if vv_name is not temperature add concentration\n",
    "if (vv_name != \"Temperature\")\n",
    "    vv_name <- paste(vv_name, \"concentration\", sep = \" \")\n",
    "vv_name <- str_to_title(vv_name)\n",
    "# add model_unit in brackets\n",
    "vv_name <- paste(vv_name, \"(\", model_unit, \")\", sep = \"\")\n",
    "\n",
    "gg <- df_zonals %>%\n",
    "    # turn variable into title\n",
    "    mutate(variable = str_to_title(variable)) %>%\n",
    "    ggplot()+\n",
    "    geom_tile(aes(lat, depth, fill = value, height = width))+\n",
    "    theme_bw(base_size = 16)+\n",
    "    facet_grid(region~variable)+\n",
    "    # coord_flip()+\n",
    "    labs(y = \"Depth (km)\", x = \"Latitude\")+\n",
    "    # x scale between -90 and 90, provide suitable labels with 30 split\n",
    "    theme(\n",
    "    legend.position = \"bottom\", legend.direction = \"horizontal\", legend.box = \"horizontal\", legend.key.width = unit(2.0, \"cm\"),\n",
    "    legend.key.height = unit(0.3, \"cm\"))+\n",
    "    scale_fill_viridis_c(na.value = \"white\",\n",
    "                       #breaks = c(0.4, 0.6, 0.8, 1.0), labels = c(\"0.4\", \"0.6\", \"0.8\", \">1\"),\n",
    "                       guide = guide_colorbar(title.position = \"bottom\", title.hjust = 0.5, title.theme = element_text(angle = 0, size = 12, family = \"Helvetica\"))\n",
    "  )+\n",
    "    labs(fill = vv_name)+\n",
    "    theme(axis.title.x = element_blank())\n",
    "    # get rid of whitespace\n",
    "\n",
    "    # put the legend\n",
    "\n",
    "x_labels <- as.numeric(na.omit(layer_scales(gg)$x$break_positions()))\n",
    "x_breaks <- x_labels\n",
    "\n",
    "x_labels <- ifelse(x_labels >= 0, paste0(x_labels, \"°N\"), paste0(abs(x_labels), \"°S\"))\n",
    "\n",
    "gg <- gg +\n",
    "    scale_x_continuous(breaks = x_breaks, labels = x_labels)\n",
    "gg\n",
    "    \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc5095e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a57547c",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if zonal_plot and nws == False:\n",
    "    if global_grid:\n",
    "        md(f\"**Figure {chapter}{i_figure}**: Zonal mean of {vv_name} for model and observations for the Atlantic and Pacific Oceans. The depth is given in km.\")\n",
    "        i_figure += 1\n",
    "    else:\n",
    "        if source == \"woa\":\n",
    "            md(f\"**Figure {chapter}{i_figure}**: Zonal mean of {vv_name} for model and observations for the full domain. The depth is given in km.\")\n",
    "            i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6940d562",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%R -i global_grid -i model_unit -i vv_name -i zonal_plot\n",
    "library(tidyverse)\n",
    "if (zonal_plot){\n",
    "    df_zonals <- arrow::read_feather(\"adhoc/df_zonals.feather\")\n",
    "# now do a bias plot\n",
    "\n",
    "df_zonals <- df_zonals %>%\n",
    "    select(lat, region, depth, variable, value) %>%\n",
    "    spread(variable, value) %>%\n",
    "    mutate(bias = model - observation)\n",
    "df_zonals <- df_zonals %>%\n",
    "    mutate(depth = -depth) %>%\n",
    "    mutate(depth = depth / 1000) %>%\n",
    "    arrange(desc(depth)) %>%\n",
    "    group_by(region,lat) %>%\n",
    "    mutate(lag = lag(depth)) %>%\n",
    "    replace_na(list(lag = 0)) %>%\n",
    "    mutate(width = depth - lag)\n",
    "\n",
    "# make vv_name a title\n",
    "# if vv_name is not temperature add concentration\n",
    "if (vv_name != \"Temperature\")\n",
    "    vv_name <- paste(vv_name, \"concentration\", sep = \" \")\n",
    "vv_name <- str_to_title(vv_name)\n",
    "# add model_unit in brackets\n",
    "vv_name <- paste(vv_name, \"(\", model_unit, \")\", sep = \"\")\n",
    "# add bias to the start\n",
    "vv_name <- paste(\"Bias in\", vv_name)\n",
    "\n",
    "df_zonals %>%\n",
    "    # turn variable into title\n",
    "    ggplot()+\n",
    "    geom_tile(aes(lat, depth, fill = bias, height = width))+\n",
    "    theme_bw(base_size = 16)+\n",
    "    facet_wrap(~region)+\n",
    "    # coord_flip()+\n",
    "    labs(y = \"Depth (km)\", x = \"Latitude\")+\n",
    "    # x scale between -90 and 90, provide suitable labels with 30 split\n",
    "    scale_x_continuous(breaks = seq(-90, 60, 30), labels = c(\"90°S\", \"60°S\", \"30°S\", \"0°\", \"30°N\", \"60°N\"), limits = c(-90, 90), expand = c(0,0))+\n",
    "    scale_y_continuous(expand = c(0,0))+\n",
    "    theme(\n",
    "    legend.position = \"bottom\", legend.direction = \"horizontal\", legend.box = \"horizontal\", legend.key.width = unit(2.0, \"cm\"),\n",
    "    legend.key.height = unit(0.3, \"cm\"))+\n",
    "    # scale_fill_gradient2(low = \"blue\", mid = \"white\", high = \"red\", midpoint = 0,\n",
    "                    #    guide = guide_colorbar(title.position = \"bottom\", title.hjust = 0.5, title.theme = element_text(angle = 0, size = 12, family = \"Helvetica\"))+\n",
    "    labs(fill = vv_name)+\n",
    "    scale_fill_gradient2(low = \"blue\", high = \"red\", guide = guide_colourbar(title.position = \"bottom\", title.hjust = 0.5, title.theme = element_text(angle = 0, size = 12, family = \"Helvetica\")))+\n",
    "        theme(axis.title.x = element_blank())\n",
    "    # get rid of whitespace\n",
    "\n",
    "    # put the legend\n",
    "    \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfed6f7c",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if zonal_plot:\n",
    "    if global_grid:\n",
    "        md(f\"**Figure {chapter}{i_figure}**: Bias in zonal mean of {vv_name} for model and observations for the Atlantic and Pacific Oceans. The depth is given in km.\")\n",
    "        i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faff526",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "time_series = False\n",
    "if regional:\n",
    "    ff = glob.glob(f\"../../matched/gridded/**/**/**_{variable}*surface.nc\")\n",
    "    ff = [x for x in ff if source in x]\n",
    "    ds_ts = nc.open_data(ff)\n",
    "    years = ds_ts.years\n",
    "    year_range = f\"{min(years)}-{max(years)}\"\n",
    "    if len(years) > 1:\n",
    "        ds_ts.tmean(\"year\")\n",
    "        ds_ts.run()\n",
    "        time_series = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3b2cfc",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if time_series:\n",
    "    md(f\"The ability of the model to reproduce mult-year trends in {layer} {vv_name} was assessed by comparing the modelled and observed time series of annual {vv_name} across each region.\")\n",
    "    md(f\"The figure below shows the average {vv_name} in each region\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c41838c",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if time_series:\n",
    "    df_all = []\n",
    "    for vv in ds_regions.variables:\n",
    "        ds_rr = ds_regions.copy()\n",
    "        ds_rr.subset(variable = vv)\n",
    "        ds_rr.run()\n",
    "        ds_vv = ds_ts.copy()\n",
    "        ds_vv * ds_rr\n",
    "        ds_region = ds_vv.copy()\n",
    "        ds_vv.spatial_mean()\n",
    "        region = list(regions_contents.query(\"variable == @vv\").long_name)[0]\n",
    "        time_name = [x for x in list(ds_vv.to_xarray().coords) if \"time\" in x][0]\n",
    "        df_vv = (\n",
    "            ds_vv\n",
    "            .to_dataframe()\n",
    "            .reset_index()\n",
    "            .rename(columns = {time_name: \"time\"})\n",
    "            .loc[:,[\"time\", \"model\", \"observation\"]]\n",
    "            .melt(\"time\")\n",
    "            .assign(year = lambda x: x.time.dt.year)\n",
    "            .assign(region = vv)\n",
    "        )\n",
    "        df_all.append(df_vv)\n",
    "        ds_region.tmean()\n",
    "        df_region = (\n",
    "            ds_region\n",
    "            .to_dataframe()\n",
    "            .dropna()\n",
    "            .reset_index()\n",
    "            .loc[:,[\"model\", \"observation\"]]\n",
    "            .drop_duplicates()\n",
    "        )\n",
    "    \n",
    "        del ds_rr, ds_vv, ds_region\n",
    "    df_all = pd.concat(df_all).dropna()\n",
    "        \n",
    "    df_all = (\n",
    "        df_all\n",
    "        .merge(df_mapped.loc[:,[\"long_name\", \"variable\"]].drop_duplicates().rename(columns = {\"variable\": \"region\"}))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfffd70",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if time_series:\n",
    "    # save df_all to csv\n",
    "    ylab = \"Spatial average \" + variable + \" (\"+ nc.static_plot.fix_label(ds_ts.contents.unit[0]) + \")\"\n",
    "    \n",
    "    gg = (\n",
    "        ggplot(df_all)+\n",
    "        geom_line(aes(\"year\", \"value\", colour = \"variable\"))+\n",
    "        facet_wrap(\"long_name\")+\n",
    "        labs(y = ylab )+\n",
    "        labs(x = \"Year\")+\n",
    "        theme(legend_position = \"top\")+\n",
    "        scale_color_manual(values = [\"red\", \"blue\"])+\n",
    "        theme_bw(base_size = 10)+\n",
    "        labs(colour = \"\")+\n",
    "        theme(legend_position = \"top\") \n",
    "        \n",
    "    )\n",
    "    \n",
    "    gg = gg.draw()\n",
    "    gg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda63af6",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if time_series:\n",
    "    md(f\"**Figure {chapter}{i_figure}**: Changes in {layer} {vv_name} for model and observations for each region for the period {year_range}. The spatial average is taken over the region.\") \n",
    "    i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280efcca",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cbb9fe",
   "metadata": {},
   "source": [
    "## Data Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a8536f",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if source == \"nsbc\":\n",
    "    md_basic(\"Hinrichs,Iris; Gouretski,Viktor; Paetsch,Johannes; Emeis, Kay; Stammer, Detlef (2017). North Sea Biogeochemical Climatology (Version 1.1).\")\n",
    "    md_basic(\"URL: <https://www.cen.uni-hamburg.de/en/icdc/data/ocean/nsbc.html>\")\n",
    "if variable == \"poc\":\n",
    "    md_basic(\"Sathyendranath, S.; Kong, C.; Jackson, T. (2021): NCEO: Monthly global Particulate Organic Carbon (POC) (produced from the Ocean Colour Climate Change Initiative, Version 4.2 dataset). Centre for Environmental Data Analysis, 07 January 2021. doi:10.5285/ef09d81517a84979ac60329e4859f449. https://dx.doi.org/10.5285/ef09d81517a84979ac60329e4859f449\")\n",
    "    md_basic(\"URL: <https://catalogue.ceda.ac.uk/uuid/ef09d81517a84979ac60329e4859f449>\")\n",
    "\n",
    "if source == \"ostia\":\n",
    "    md_basic(\"Good, S.; Fiedler, E.; Mao, C.; Martin, M.J.; Maycock, A.; Reid, R.; Roberts-Jones, J.; Searle, T.; Waters, J.; While, J.; Worsfold, M. The Current Configuration of the OSTIA System for Operational Production of Foundation Sea Surface Temperature and Ice Concentration Analyses. Remote Sens. 2020, 12, 720, doi:10.3390/rs12040720\")\n",
    "    md_basic(\"URL: <https://data.marine.copernicus.eu/product/SST_GLO_SST_L4_REP_OBSERVATIONS_010_011/description>\")\n",
    "    md_basic(\"From 2022 onwards, the near-real time product is used: <https://data.marine.copernicus.eu/product/SST_GLO_SST_L4_NRT_OBSERVATIONS_010_001/description>\")\n",
    "\n",
    "if source == \"cobe2\":\n",
    "    md_basic(\"COBE-SST 2 and Sea Ice data provided by the NOAA PSL, Boulder, Colorado, USA, from their website at <https://psl.noaa.gov>.\")\n",
    "\n",
    "if source == \"woa\":\n",
    "    md_basic(\"Reagan, James R.; Boyer, Tim P.; García, Hernán E.; Locarnini, Ricardo A.; Baranova, Olga K.; Bouchard, Courtney; Cross, Scott L.; Mishonov, Alexey V.; Paver, Christopher R.; Seidov, Dan; Wang, Zhankun; Dukhovskoy, Dmitry (2023). World Ocean Atlas 2023 (NCEI Accession 0270533). [indicate subset used]. NOAA National Centers for Environmental Information. Dataset. <https://www.ncei.noaa.gov/archive/accession/0270533>. Accessed 13/05/2024.\")\n",
    "\n",
    "if global_grid:\n",
    "    md_basic(\"Regional subdomains were based on mapped regions from the Marine Regions database. The Marine Regions database is available at <http://www.marineregions.org>.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a95ea54",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if test_status:\n",
    "    md(\"This is getting to the end!\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
