{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20ea649e",
   "metadata": {},
   "source": [
    "# Ability of models to reproduce seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224944b6",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe6c2b7",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# model_dict = {\n",
    "#     \"LOCATE\":\"/data/proteus1/scratch/gle/getmval/locate\",\n",
    "#     \"GETM\":\"/data/proteus1/scratch/rwi/adhoc/getm/3dmn\"\n",
    "# }\n",
    "\n",
    "model_dict = model_dict_str\n",
    "num_models = len(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c445cc99",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "annual_paths = []\n",
    "for key in model_dict:\n",
    "    if not os.path.exists(model_dict[key] + \"/results/temporals/\"):\n",
    "        raise ValueError(\"No annual mean folder found for \" + key)\n",
    "    paths = glob.glob(model_dict[key] + \"/results/temporals/*\")\n",
    "    paths = tidy_summary_paths(paths)\n",
    "    annual_paths.append(\n",
    "        pd.DataFrame({\"path\": paths})\n",
    "        .assign(model = key)\n",
    "    )\n",
    "\n",
    "annual_paths = pd.concat(annual_paths)\n",
    "\n",
    "annual_paths[\"base_name\"] = annual_paths[\"path\"].apply(lambda x: os.path.basename(x))\n",
    "# only interested in netcdf file in path\n",
    "annual_paths = annual_paths[annual_paths[\"base_name\"].str.contains(\".nc\")]\n",
    "annual_paths[\"base_name\"] = annual_paths[\"base_name\"].apply(fix_basename)\n",
    "\n",
    "\n",
    "i_figure = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5295b3c1",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "annual_paths = (\n",
    "    annual_paths\n",
    "    .groupby(\"base_name\")\n",
    "    .count()\n",
    "      .query(\"model > 1\")\n",
    "      .reset_index()\n",
    "      .drop(columns = [\"path\", \"model\"])\n",
    "      .merge(annual_paths)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b61904",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "base_names = annual_paths.base_name.unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf964f4a",
   "metadata": {
    "tags": [
     "remove-cell",
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "output = dict()\n",
    "text_output = dict()\n",
    "# list to track data frames with correlation coefficients\n",
    "df_cor = []\n",
    "for bb in base_names:\n",
    "    variable = bb.split(\"_\")[0].replace(\".nc\", \"\")\n",
    "    bb_paths = annual_paths.query(\"base_name == @bb\").reset_index(drop = True)\n",
    "    n_cols = len(bb_paths)\n",
    "    # generate the mask first\n",
    "\n",
    "    ds_mask = nc.open_data(bb_paths.path[0])\n",
    "    ds_mask.subset(variable = \"cor\")\n",
    "    ds_mask.run()\n",
    "    for ff in bb_paths.path[1:]:\n",
    "        ds_ff = nc.open_data(ff)\n",
    "        ds_ff.subset(variable = \"cor\")\n",
    "        ds_ff.regrid(ds_mask, \"nn\")\n",
    "        ds_mask * ds_ff\n",
    "        ds_mask.run()\n",
    "        ds_mask.abs()\n",
    "        ds_mask > 0\n",
    "        ds_mask.run()\n",
    "    df_mask = (\n",
    "        ds_mask.to_dataframe()\n",
    "        .dropna()\n",
    "        .reset_index()\n",
    "    )\n",
    "    lon_name = [x for x in df_mask.columns if \"lon\" in x][0]\n",
    "    lat_name = [x for x in df_mask.columns if \"lat\" in x][0]\n",
    "    #rename\n",
    "    df_mask = df_mask.rename(columns = {lon_name: \"lon\", lat_name: \"lat\"})\n",
    "    lon_min = df_mask.lon.min()\n",
    "    lon_max = df_mask.lon.max()\n",
    "    lat_min = df_mask.lat.min()\n",
    "    lat_max = df_mask.lat.max()\n",
    "    lons = [lon_min, lon_max]\n",
    "    lats = [lat_min, lat_max]\n",
    "    # coerse to float\n",
    "    lons = [float(x) for x in lons]\n",
    "    lats = [float(x) for x in lats]\n",
    "    ds_mask.subset(lon = lons, lat = lats)\n",
    "    ds_mask.run()\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.subplots_adjust(wspace=20, hspace=20)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "    # Create 4x4 Grid\n",
    "    key = md(f\"## Seasonality of sea surface {fix_variable_name(variable)}\")\n",
    "\n",
    "    gs = fig.add_gridspec(nrows=1, ncols=num_models, wspace = 0.45, hspace = 0)\n",
    "    # get the minimum and maximum values for the colorbar\n",
    "\n",
    "    z_max = -1\n",
    "    z_min = 1\n",
    "\n",
    "\n",
    "    for i in range(0, len(bb_paths)):\n",
    "        ds = nc.open_data(bb_paths.path[i])\n",
    "        ds.subset(variable = \"cor\")\n",
    "        ds.regrid(ds_mask, \"nn\")\n",
    "        ds * ds_mask\n",
    "        ds.run()\n",
    "        i_max = ds.to_dataframe().dropna().reset_index().cor.max()\n",
    "        i_min = ds.to_dataframe().dropna().reset_index().cor.min()\n",
    "        if i_max > z_max:\n",
    "            z_max = i_max\n",
    "        if i_min < z_min:\n",
    "            z_min = i_min\n",
    "\n",
    "\n",
    "    for i in range(0, len(bb_paths)):\n",
    "        ds = nc.open_data(bb_paths.path[i])\n",
    "        ds.subset(variable = \"cor\")\n",
    "        ds.regrid(ds_mask, \"nn\")\n",
    "        ds * ds_mask\n",
    "        ds.run()\n",
    "        #get the model run name\n",
    "        model_name = bb_paths.model[i]\n",
    "        ds.to_latlon(lon = lons, lat = lats, res = [0.111, 0.067]) \n",
    "        ds.pub_plot(  fig = fig, gs = gs[0,i], title = model_name, limits = [z_min, z_max])\n",
    "        ds.spatial_mean()\n",
    "        cor_value = ds.to_dataframe().dropna().reset_index().cor[0]\n",
    "        # stick this in a dataframme\n",
    "        df_cor.append(\n",
    "            pd.DataFrame({\"model\": [model_name], \"variable\": variable, \"cor\": cor_value})\n",
    "        )\n",
    "    output[key] = fig \n",
    "    name1 = bb_paths.base_name[0].split(variable)[1].split(\"_\")[-1].replace(\".nc\", \"\")\n",
    "    name2 = bb_paths.base_name[1].split(variable)[1].split(\"_\")[-1].replace(\".nc\", \"\")\n",
    "    comp_text = None\n",
    "    if name1 == name2:\n",
    "        if len(name1) > 0 and name1 != \"cor\":\n",
    "            source = name1.upper()\n",
    "            comp_text = f\"Correlations coefficients were calculated using monthly averages in the simulations ands the observational data from **{source}**.\"\n",
    "    text_output[key] = comp_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d797100d",
   "metadata": {
    "tags": [
     "remove-input",
     "hide-code"
    ]
   },
   "outputs": [],
   "source": [
    "for key in output:\n",
    "    key\n",
    "    if text_output[key] is not None:\n",
    "        display(md(text_output[key]))\n",
    "    display(output[key])\n",
    "    # coerce key to str\n",
    "    key_str = str(key)\n",
    "    md(f\"**Figure {i_figure}**: Correlation coefficient between models and observations in each grid cell and each climatological month.\")\n",
    "    i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b406c18",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "df_cor = pd.concat(df_cor)\n",
    "df_pivot = (\n",
    "    df_cor.pivot(index = \"variable\", columns = \"model\", values = \"cor\").reset_index()\n",
    ")\n",
    "for i in range(0, len(df_pivot)):\n",
    "    # add a star to the highest value in each row\n",
    "    max_value = df_pivot.iloc[i, 1:].max()\n",
    "    for j in range(1, len(df_pivot.columns)):\n",
    "        if df_pivot.iloc[i, j] == max_value:\n",
    "            # use markdown to bold the value\n",
    "            df_pivot.iloc[i, j] = f\"{df_pivot.iloc[i, j]:.3g}**\"\n",
    "            # df_pivot.iloc[i, j] = f\"**{df_pivot.iloc[i, j]}**\" \n",
    "            # df_pivot.iloc[i, j] = f\"**{df_pivot.iloc[i, j]}**\"\n",
    "        else:\n",
    "            df_pivot.iloc[i, j] = f\"{df_pivot.iloc[i, j]:.3g}\"\n",
    "# make everything a string\n",
    "df_pivot = df_pivot.astype(str)\n",
    "df_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbfe54b",
   "metadata": {},
   "source": [
    "## Overall summary of temporal performance of simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe29ab01",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# spread model and cor in columns\n",
    "df_display(\n",
    "    df_pivot\n",
    ")\n",
    "md(f\"**Table {i_table}**: Spatial average of correlation coefficients between models and observations for each simulation and each variable.\")\n",
    "i_table += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
