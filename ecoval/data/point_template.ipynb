{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation of point_layer template_title using point observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# bin_value using function from r4ecology's github\n",
    "import numpy as np\n",
    "def bin_value(x, bin_res):\n",
    "    return np.floor((x + bin_res / 2) / bin_res + 0.5) * bin_res - bin_res / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "variable = \"point_variable\".lower()\n",
    "vv_name = variable\n",
    "if vv_name in [\"benbio\", \"carbon\", \"susfrac\", \"oxycons\"]:\n",
    "    compact = True\n",
    "if vv_name.lower() == \"ph\":\n",
    "    vv_name = \"pH\"\n",
    "if vv_name in [\"doc\", \"poc\"]:\n",
    "    vv_name = vv_name.upper()\n",
    "if vv_name == \"benbio\":\n",
    "    vv_name = \"biomass of macrobenthos\"\n",
    "if vv_name == \"susfrac\":\n",
    "    vv_name = \"Suspension feeding fraction\"\n",
    "if vv_name == \"oxycons\":\n",
    "    vv_name = \"benthic oxygen consumption\"\n",
    "if vv_name == \"mesozoo\":\n",
    "    vv_name = \"mesozooplankton concentration\"\n",
    "layer = \"point_layer\"\n",
    "# get the units. File inspection could be randomized in case people have put loose files in there...\n",
    "import glob\n",
    "df = pd.read_csv(\"../../matched/mapping.csv\")\n",
    "df = df.query(\"variable == @variable\")\n",
    "pattern = list(df.pattern)[0]\n",
    "paths = pd.read_csv(glob.glob(f\"../../matched/point/**/{layer}/{variable}/paths.csv\")[0]).path\n",
    "\n",
    "unit = None\n",
    "if unit is None:\n",
    "    try:\n",
    "        ff = glob.glob(f\"../../matched/point/**/{layer}/{variable}/*_{variable}_unit.csv\")[0]\n",
    "        df = pd.read_csv(ff)\n",
    "        unit = df.unit[0]\n",
    "    except:\n",
    "        pass\n",
    "if unit is None:\n",
    "    for ff in paths:\n",
    "        try:\n",
    "            ds = nc.open_data(paths[0])\n",
    "            model_variable = list(df.model_variable)[0].split(\"+\")[0]\n",
    "            unit = list(ds.contents.query(\"variable == @model_variable\").unit)[0]\n",
    "            break\n",
    "        except:\n",
    "            pass\n",
    "if unit is None:\n",
    "    unit = \"unknown unit\"\n",
    "\n",
    "if variable == \"carbon\":\n",
    "    unit = \"kg m-3\"\n",
    "if variable == \"pco2\":\n",
    "    unit = \"µatm\"\n",
    "\n",
    "if unit.endswith(\"/d\"):\n",
    "    unit = unit[:-2] + \"/day\"\n",
    "\n",
    "if variable == \"susfrac\":\n",
    "    unit = \"-\"\n",
    "if variable == \"chlorophyll\":\n",
    "    # ensure there is a space after mg in unit, using regex\n",
    "    unit = \"mg /m^3\"\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "## Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if layer in [\"surface\", \"all\"]:\n",
    "    md(f\"## Performance of model {vv_name} at the sea surface\")\n",
    "    layer_select = \"surface\"\n",
    "if layer in [\"benthic\"]:\n",
    "    md(f\"## Performance of model {vv_name} in the sediment layer\")\n",
    "    layer_select = \"surface\"\n",
    "chunk_point_surface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if layer in [\"bottom\", \"all\"]:\n",
    "    md(f\"## Performance of model {variable} at the near-bottom\")\n",
    "    layer_select = \"bottom\"\n",
    "chunk_point_bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if layer == \"all\":\n",
    "    md(f\"## Depth-resolved comparisons of modelled and observed {vv_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "df_raw =  pd.read_csv(glob.glob(f\"../../matched/point/**/{layer}/{variable}/*_{variable}.csv\")[0])\n",
    "ff = \"../../matched/model_grid.nc\"\n",
    "if not os.path.exists(ff):  \n",
    "    ff = \"../../matched/model_bathymetry.nc\"\n",
    "import nctoolkit as nc\n",
    "ds_coords = nc.open_data(ff)\n",
    "ds_coords.rename({ds_coords.variables[0]: \"e3t\"})\n",
    "ds_coords.assign(lon_model = lambda x: lon(x.e3t), lat_model = lambda x: lat(x.e3t))\n",
    "ds_coords.drop(variables = \"e3t\")\n",
    "ds_coords.run()\n",
    "ds_coords.regrid(df_raw.loc[:,[\"lon\", \"lat\"]].drop_duplicates(), method = \"nearest\")\n",
    "df_coords = ds_coords.to_dataframe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if layer == \"all\":\n",
    "    # overall summary\n",
    "    #df_raw\n",
    "    # create bins\n",
    "    # 0-10m\n",
    "    # 10-30m\n",
    "    # 30-60m\n",
    "    # 60-100m\n",
    "    # 100-150m\n",
    "    # 150-300m\n",
    "    # 300-600m\n",
    "    # 600-1000m\n",
    "    # function\n",
    "    def bin_depth(x):\n",
    "        if x <= 10:\n",
    "            return \"0-10m\"\n",
    "        if x <= 30:\n",
    "            return \"10-30m\"\n",
    "        if x <= 60:\n",
    "            return \"30-60m\"\n",
    "        if x <= 100:\n",
    "            return \"60-100m\"\n",
    "        if x <= 150:\n",
    "            return \"100-150m\"\n",
    "        if x <= 300:\n",
    "            return \"150-300m\"\n",
    "        if x <= 600:\n",
    "            return \"300-600m\"\n",
    "        if x <= 1000:\n",
    "            return \"600-1000m\"\n",
    "        return \">1000m\"\n",
    "\n",
    "    df_ave = (df_raw.merge(df_coords))\n",
    "    selection = [x for x in [\"lon_model\", \"lat_model\", \"month\", \"year\", \"day\", \"depth\", \"model\", \"observation\"] if x in df_ave.columns]\n",
    "    df_ave = df_ave.loc[:,selection]\n",
    "    grouping = [x for x in [\"lon_model\", \"lat_model\", \"month\", \"year\", \"day\", \"depth\"] if x in df_ave.columns]\n",
    "    df_ave = (\n",
    "        df_ave\n",
    "        .groupby(grouping)\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_binned = (\n",
    "        df_ave\n",
    "    )\n",
    "    df_mapped = (\n",
    "        df_raw\n",
    "        .assign(depth = lambda x: x.depth.apply(bin_depth))\n",
    "        .loc[:,[\"lon\", \"lat\", \"depth\"]]\n",
    "        .drop_duplicates()\n",
    "        .reset_index(drop = True)   \n",
    "\n",
    "    )\n",
    "    df_summary = (\n",
    "        df_binned\n",
    "        .groupby([\"lon_model\", \"lat_model\",  \"depth\"])\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .assign(depth = lambda x: x.depth.apply(bin_depth))\n",
    "        .groupby(\"depth\")\n",
    "        # calculate bias, cor and rmsd between model and observation, and number of observations\n",
    "        .apply(lambda x: pd.Series({\"bias\": x.model.mean() - x.observation.mean(), \"cor\": x.model.corr(x.observation), \"rmsd\": np.sqrt(((x.model - x.observation).pow(2)).mean()), \"n\": len(x)}))   \n",
    "        .reset_index()\n",
    "        # sort depth in original order\n",
    "    )\n",
    "    # now do the same but for depths < 150m\n",
    "    df_summary_shallow = (\n",
    "        df_ave\n",
    "        .query(\"depth < 150\") \n",
    "        .groupby(grouping)\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .groupby([\"lon_model\", \"lat_model\",  \"depth\"])\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .assign(depth = \"0-150m\")\n",
    "        .groupby(\"depth\")\n",
    "        # calculate bias, cor and rmsd between model and observation\n",
    "        .apply(lambda x: pd.Series({\"bias\": x.model.mean() - x.observation.mean(), \"cor\": x.model.corr(x.observation), \"rmsd\": np.sqrt(((x.model - x.observation).pow(2)).mean()), \"n\": len(x)}))   \n",
    "        .reset_index()\n",
    "    )\n",
    "    # bind them\n",
    "    df_summary = pd.concat([df_summary, df_summary_shallow])\n",
    "    df_summary = df_summary.reset_index()\n",
    "    # make the titles better\n",
    "    df_summary = df_summary.rename(columns={\"depth\": \"Depth\", \"bias\": \"Bias\", \"cor\": \"Correlation\", \"rmsd\": \"RMSD\", \"n\": \"Number of observations\"})\n",
    "    df_summary = df_summary.drop(columns = \"index\")\n",
    "    df_summary = df_summary.assign(Depth = pd.Categorical(df_summary.Depth, [\"0-150m\",\"0-10m\", \"10-30m\", \"30-60m\", \"60-100m\", \"100-150m\", \"150-300m\", \"300-600m\", \"600-1000m\", \">1000m\"]))\n",
    "    df_summary = df_summary.sort_values(\"Depth\")\n",
    "else:\n",
    "    df_mapped = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "map_layer = False\n",
    "if layer == \"all\":\n",
    "    map_layer = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%%R -i df_mapped -i map_layer\n",
    "options(warn=-1)\n",
    "options(warn=-1)\n",
    "library(tidyverse)\n",
    "library(ggtext)\n",
    "\n",
    "if (map_layer){\n",
    "\n",
    "\n",
    "# make depth a factor\n",
    "df_mapped <- df_mapped %>%\n",
    "    mutate(depth = factor(depth, levels = c(\"0-10m\", \"10-30m\", \"30-60m\", \"60-100m\", \"100-150m\", \"150-300m\", \"300-600m\", \"600-1000m\", \">1000m\")))\n",
    "\n",
    "gg <- df_mapped %>%\n",
    "    ggplot()+\n",
    "    geom_point(aes(lon, lat), size = 0.2)+\n",
    "    theme_gray(base_size = 14)+\n",
    "    coord_fixed(ratio = 1.5, xlim = c(min(df_mapped$lon), max(df_mapped$lon)), ylim = c(min(df_mapped$lat), max(df_mapped$lat))) +\n",
    "    facet_wrap(~depth)\n",
    "\n",
    "\n",
    "y_labels <-  as.numeric(na.omit(layer_scales(gg)$y$break_positions()))\n",
    "x_labels <- as.numeric(na.omit(layer_scales(gg)$x$break_positions()))\n",
    "x_breaks <- x_labels\n",
    "y_breaks <- y_labels\n",
    "\n",
    "# y labels are north-south coordinates. Make them more appropriate\n",
    "# i.e. 10 should be 10 °N, -10 should be 10 °S\n",
    "\n",
    "y_labels <- ifelse(y_labels >= 0, paste0(y_labels, \"°N\"), paste0(abs(y_labels), \"°S\"))\n",
    "x_labels <- ifelse(x_labels >= 0, paste0(x_labels, \"°E\"), paste0(abs(x_labels), \"°W\"))\n",
    "\n",
    "gg <- gg + scale_x_continuous(breaks = x_breaks, labels = x_labels) + scale_y_continuous(breaks = y_breaks, labels = y_labels)+\n",
    "    geom_polygon(data = world_map, aes(long, lat, group = group), fill = \"grey60\")\n",
    "\n",
    "# remove x and y axis names\n",
    "gg <- gg +\n",
    "    labs(x = \"\", y = \"\") \n",
    "\n",
    "# ditch the whitespace around the plot\n",
    "gg <- gg + theme(plot.margin=unit(c(0,0,0,0),\"cm\"))\n",
    "gg\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if layer == \"all\":\n",
    "    md(f\"**Figure {chapter}{i_figure}**: The geographic distribution of matchups between the model and observational {variable}. The data has been binned into depth ranges. The depth ranges are 0-10m, 10-30m, 30-60m, 60-100m, 100-150m, 150-300m, 300-600m, 600-1000m, and >1000m. The number of observations in each depth range is shown in the tables below.\")\n",
    "    i_figure += 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if layer == \"all\":\n",
    "    df_display(df_summary)\n",
    "    # save this to csv in the results directory\n",
    "    ff_out = f\"../../results/{variable}_depth_summary.csv\"\n",
    "    df_summary.assign(unit = unit).to_csv(ff_out, index = False)\n",
    "    \n",
    "    md(f\"**Table {chapter}{i_table}:** Average bias ({unit}), root-mean square difference (RMSD) and correlation coefficient of modelled and observed {vv_name} for different depth ranges. The bias is calculated as model - observation. The RMSD is the square root of the mean squared difference. The correlation coefficient is the Pearson correlation coefficient between the model and observed values.\")\n",
    "    i_table += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "## Data Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if variable == \"poc\":\n",
    "    md_basic(\"Boss, Emmanuel; Picheral, Marc; Searson, Sarah; Le Goff, Hervé; Reverdin, Gilles; Leeuw, Thomas; Chase, Alison P; Bricaud, Annick; Kolber, Zbigniew S; Taillandier, V; Pesant, Stephane; Tara Oceans Consortium, Coordinators; Tara Oceans Expedition, Participants (2017): Underway surface water data during the Tara Oceans expedition in 2009-2012 [dataset]. PANGAEA, https://doi.org/10.1594/PANGAEA.873566, In: Boss, Emmanuel; Picheral, Marc; Searson, Sarah; Marec, Claudie; Le Goff, Hervé; Reverdin, Gilles; Leeuw, Thomas; Chase, Alison P; Anderson, Leif G; Gattuso, Jean-Pierre; Pino, Diana Ruiz; Padín, Xose Antonio; Grondin, Pierre-Luc; Matuoka, Atsushi; Babin, Marcel; Bricaud, Annick; Kolber, Zbigniew S; Taillandier, V; Hafez, Mark; Chekalyuk, Alexander; Pesant, Stephane; Météo France; Tara Oceans Consortium, Coordinators (2017): Harmonised data from underway navigation, meteorology and surface water measurements during the Tara Oceans expedition in 2009-2013 [dataset publication series]. PANGAEA, <https://doi.org/10.1594/PANGAEA.873592>\")\n",
    "    md_basic(\"Röttgers, Rüdiger; Bi, Shun; Burmester, Henning; Heymann, Kerstin; Hieronymi, Martin; Krasemann, Hajo; Schönfeld, Wolfgang (2023): Water inherent optical properties and concentrations of water constituents from the German Bight and adjacent regions: concentrations and auxiliary data [dataset]. PANGAEA, https://doi.org/10.1594/PANGAEA.950767, In: Röttgers, Rüdiger; Bi, Shun; Burmester, Henning; Heymann, Kerstin; Hieronymi, Martin; Krasemann, Hajo; Schönfeld, Wolfgang (2023): Water inherent optical properties and concentrations of water constituents from the German Bight and adjacent regions [dataset bundled publication]. PANGAEA, <https://doi.org/10.1594/PANGAEA.950774>)\")\n",
    "    md_basic(\"Loisel, Hubert; Duforêt-Gaurier, Lucile; Tran, Trung Kien; Jorge, Daniel S F; Steinmetz, Francois; Mangin, Antoine; Bretagnon, Marine; d'Andon, Odile (2023): Database (DSM) of in situPOC, SPM and Rrs collected between 1997 and 2018 [dataset]. PANGAEA, <https://doi.org/10.1594/PANGAEA.960962>\")\n",
    "    md_basic(\"Lønborg, Christian; Carreira, Cátia; Abril, Gwenael; Agustí, Susana; Amaral, Valentina; Andersson, Agneta; Arístegui, Javier; Bhadury, Punyasloke; Bif, Mariana B; Borges, Alberto Vieira; Bouillon, Steven; Calleja, Maria Ll; Cotovicz, Luiz C Jr; Cozzi, Stefano; Doval, Maryló; Duarte, Carlos Manuel; Eyre, Bradley D; Fichot, Cedric; García-Martín, Elena; Garzon-Garcia, Alexandra; Giani, Michele; Gonçalves-Araujo, Rafael; Gruber, Renee K; Hansell, Dennis A; Hashihama, Fuminori; He, Ding; Holding, Johnna M; Hunter, William Ross; Ibánhez, J Severino; Ibello, Valeria; Jiang, Shan; Kim, Guebuem; Klun, Katja; Kowalczuk, Piotr; Kubo, Atsushi; Lee, Choon Weng; Lopes, Claudia B; Maggioni, Federica; Magni, Paolo; Marrasé, Celia; Martin, Patrick; McCallister, S Leigh; McCallum, Rosh; M Medeiros, Patricia; G Morán, Xosé Anxelu; Muller-Karger, Frank; Myers-Pigg, Allison; Norli, Marit; Oakes, Joanne M; Osterholz, Helena; Park, Hyekyung; Lund Paulsen, Maria; Rosentreter, Judith A; Ross, Jeff; Rueda-Roa, Digna; Santinelli, Chiara; Shen, Yuan; Teira, Eva; Tinta, Tinkara; Uher, Guenther; Wakita, Masahide; Ward, Nicholas D; Watanabe, Kenta; Xin, Yu; Yamashita, Youhei; Yang, Liyang; Yeo, Jacob; Yuan, Huamao; Zheng, Qiang; Álvarez‐Salgado, Xosé Antón (2023): A global database of dissolved organic matter (DOM) concentration measurements in coastal waters (CoastDOM v.1) [dataset]. PANGAEA, <https://doi.org/10.1594/PANGAEA.964012>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if vv_source.lower() == \"ices\":\n",
    "    md_basic(\"ICES Data Portal, Dataset on Ocean HydroChemistry, Extracted March 3, 2023. ICES, Copenhagen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if variable == \"carbon\":\n",
    "    md_basic('Diesing, Markus, Terje Thorsnes, and Lilja Rún Bjarnadóttir. \"Organic carbon densities and accumulation rates in surface sediments of the North Sea and Skagerrak.\" Biogeosciences 18.6 (2021): 2139-2160.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if vv_source.lower() == \"socat23\":\n",
    "    md_basic(\"Bakker, Dorothee C. E.; Alin, Simone R.; Bates, Nicholas; Becker, Meike; Feely, Richard A.; Gkritzalis, Thanos; Jones, Steve D.; Kozyr, Alex; Lauvset, Siv K.; Metzl, Nicolas; Munro, David R.; Nakaoka, Shin-ichiro; Nojiri, Yukihiro; O'Brien, Kevin M.; Olsen, Are; Pierrot, Denis; Rehder, Gregor; Steinhoff, Tobias; Sutton, Adrienne J.; Sweeney, Colm; Tilbrook, Bronte; Wada, Chisato; Wanninkhof, Rik; Akl, John; Barbero, Leticia; Beatty, Cory M.; Berghoff, Carla F.; Bittig, Henry C.; Bott, Randy; Burger, Eugene F.; Cai, Wei-Jun; Castaño-Primo, Rocío; Corredor, Jorge E.; Cronin, Margot; De Carlo, Eric H.; DeGrandpre, Michael D.; Dietrich, Colin; Drennan, William M.; Emerson, Steven R.; Enochs, Ian C.; Enyo, Kazutaka; Epherra, Lucía; Evans, Wiley; Fiedler, Björn; Fontela, Marcos; Frangoulis, Constantin; Gehrung, Martina; Giannoudi, Louisa; Glockzin, Michael; Hales, Burke; Howden, Stephan D.; Ibánhez, J. Severino P.; Kamb, Linus; Körtzinger, Arne; Lefèvre, Nathalie; Lo Monaco, Claire; Lutz, Vivian A.; Macovei, Vlad A.; Maenner Jones, Stacy; Manalang, Dana; Manzello, Derek P.; Metzl, Nicolas; Mickett, John; Millero, Frank J.; Monacci, Natalie M.; Morell, Julio M.; Musielewicz, Sylvia; Neill, Craig; Newberger, Tim; Newton, Jan; Noakes, Scott; Ólafsdóttir, Sólveig Rósa; Ono, Tsuneo; Osborne, John; Padín, Xose A.; Paulsen, Melf; Perivoliotis, Leonidas; Petersen, Wilhelm; Petihakis, George; Plueddemann, Albert J.; Rodriguez, Carmen; Rutgersson, Anna; Sabine, Christopher L.; Salisbury, Joseph E.; Schlitzer, Reiner; Skjelvan, Ingunn; Stamataki, Natalia; Sullivan, Kevin F.; Sutherland, Stewart C.; T'Jampens, Michiel; Tadokoro, Kazuaki; Tanhua, Toste; Telszewski, Maciej; Theetaert, Hannelore; Tomlinson, Michael; Vandemark, Douglas; Velo, Antón; Voynova, Yoana G.; Weller, Robert A.; Whitehead, Chris; Wimart-Rousseau, Cathy (2023). Surface Ocean CO2 Atlas Database Version 2023 (SOCATv2023) (NCEI Accession 0278913). [indicate subset used]. NOAA National Centers for Environmental Information. Dataset. <https://doi.org/10.25921/r7xa-bt92>. Accessed [25/04/2024].\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if variable == \"doc\":\n",
    "    md_basic(\"Hansell, Dennis A.; Carlson, Craig A.; Amon, Rainer M. W.; Álvarez-Salgado, X. Antón; Yamashita, Youhei; Romera-Castillo, Cristina; Bif, Mariana B. (2021). Compilation of dissolved organic matter (DOM) data obtained from global ocean observations from 1994 to 2021. Version 2 (NCEI Accession 0227166). [indicate subset used]. NOAA National Centers for Environmental Information. Dataset. <https://doi.org/10.25921/s4f4-ye35>. Accessed [date].\")\n",
    "\n",
    "    md_basic(\"Lønborg, C., Carreira, C., Abril, G., Agustí, S., Amaral, V., Andersson, A., ... & Álvarez-Salgado, X. A. (2024). A global database of dissolved organic matter (DOM) concentration measurements in coastal waters (CoastDOM v1). Earth System Science Data, 16(2), 1107-1119.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if variable in [\"benbio\", \"susfrac\"]:\n",
    "    md_basic(\"URL: <https://www.vliz.be/vmdcdata/nsbs/about.php>\")\n",
    "if variable == \"oxycons\":\n",
    "    md_basic(\"Stratmann, Tanja; Soetaert, Karline; Wei, Chih-Lin et al. (2022). Data from: The SCOC database – a large, open and global database with sediment community oxygen consumption rates [Dataset]. Dryad. <https://doi.org/10.5061/dryad.25nd083>\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if test_status:\n",
    "    md(\"This is getting to the end!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "validation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
