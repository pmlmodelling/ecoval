{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation of sea surface PFTs using point observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# bin_value using function from r4ecology's github\n",
    "import numpy as np\n",
    "def bin_value(x, bin_res):\n",
    "    return np.floor((x + bin_res / 2) / bin_res + 0.5) * bin_res - bin_res / 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "variable = \"pft\".lower()\n",
    "vv_name = variable\n",
    "if vv_name.lower() == \"ph\":\n",
    "    vv_name = \"pH\"\n",
    "if vv_name in [\"doc\", \"poc\"]:\n",
    "    vv_name = vv_name.upper()\n",
    "if vv_name == \"benbio\":\n",
    "    vv_name = \"biomass of macrobenthos\"\n",
    "layer = \"surface\"\n",
    "# get the units. File inspection could be randomized in case people have put loose files in there...\n",
    "import glob\n",
    "df = pd.read_csv(\"../../matched/mapping.csv\")\n",
    "if variable == \"pft\":\n",
    "    df = df.query(\"variable == 'chlorophyll'\")\n",
    "else:\n",
    "    df = df.query(\"variable == @variable\")\n",
    "pattern = list(df.pattern)[0]\n",
    "paths = pd.read_csv(glob.glob(f\"../../matched/point/**/{layer}/{variable}/paths.csv\")[0]).path\n",
    "\n",
    "for ff in paths:\n",
    "    try:\n",
    "        ds = nc.open_data(paths[0])\n",
    "        model_variable = list(df.model_variable)[0].split(\"+\")[0]\n",
    "        unit = list(ds.contents.query(\"variable == @model_variable\").unit)[0]\n",
    "        break\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "## Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input",
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "ff = glob.glob(f\"../../matched/point/**/{layer}/{variable}/*_{variable}.csv\")[0]\n",
    "vv_source = os.path.basename(ff).split(\"_\")[0]\n",
    "vv_source = vv_source.upper()\n",
    "df = pd.read_csv(ff)\n",
    "if variable == \"ph\":\n",
    "    df = df.query(\"observation > 4\").reset_index(drop = True)\n",
    "# Danish part is always dubious\n",
    "df = df.query(\"lon < 9\")\n",
    "# ds= nc.open_data(f\"{data_dir}/amm7_val_subdomains.nc\")\n",
    "# ds.subset(variable = \"Shelf\")\n",
    "# ds.as_missing(0)\n",
    "# ds.regrid(df.loc[:,[\"lon\", \"lat\"]].drop_duplicates().reset_index(drop = True), \"nn\")\n",
    "# df_grid = ds.to_dataframe().reset_index().dropna().drop_duplicates()\n",
    "# df = df.merge(df_grid)\n",
    "df_locs = df.loc[:,[\"lon\", \"lat\"]].drop_duplicates()\n",
    "# bin to 0.01 resolution\n",
    "df_raw = df\n",
    "df[\"lon\"] = df[\"lon\"].apply(lambda x: bin_value(x, 0.5))\n",
    "df[\"lat\"] = df[\"lat\"].apply(lambda x: bin_value(x, 0.5))\n",
    "if \"year\" in df.columns:\n",
    "    df = df.groupby([\"lon\", \"lat\", \"year\", \"month\"]).mean().reset_index()\n",
    "else:\n",
    "    df = df.groupby([\"lon\", \"lat\"]).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if variable == \"carbon\":\n",
    "    md(\"**Note**: This is in progress. Model and observation data are yet to be converted to comparable units!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown as md\n",
    "\n",
    "if vv_source == \"ices\": \n",
    "\n",
    "    if layer == \"bottom\":\n",
    "        md(f\"Near-bottom values of {vv_name} were extracted from ICES bottle and CTD data.\")\n",
    "    if layer == \"surface\":\n",
    "        md(f\"Values from the top 5 m of the water column were extracted from ICES bottle and CTD data.\")\n",
    "    if layer == \"benthic\":\n",
    "        md(\"Benthic values were extracted from existing datasets\")\n",
    "\n",
    "\n",
    "if layer == \"bottom\":\n",
    "    md(f\"This data was extracted from vertical profiles. The near-bottom value was defined as the value closest to the bottom, that was within 5 m of the bottom. Bathymetry was estimated using GEBCO Bathymetry data.\")\n",
    "if layer == \"surface\":\n",
    "    md(f\"This data was extracted from vertical profiles. Values from the top 5 m were extracted from the database. This was compared with the model values from the sea surface level.\")\n",
    "if variable in [\"benbio\"]:\n",
    "    md(\"Biomass data for macrobenthos was downloaded from the North Sea Benthos Survey 1986.\")\n",
    "\n",
    "if variable in [\"carbon\"]:\n",
    "    md(\"Carbon data was compiled from multiple sources\")\n",
    "md(f\"In total there were {len(df)} {layer} values extracted from the observational database.\")\n",
    "\n",
    "if layer == \"bottom\":\n",
    "    md(\"**Note:** this analysis has been restricted to observations on the shelf region.\")\n",
    "\n",
    "\n",
    "if variable == \"poc\":\n",
    "    md(\"Particulate organic carbon data was compiled from multiple sources\")\n",
    "\n",
    "if variable == \"pco2\":\n",
    "    md(\"The variable pCO2water_SST_wet was extracted from the SOCAT 2023 database.\")\n",
    "    md(\"Observational values were averaged for each day in the year.\")\n",
    "\n",
    "if variable == \"doc\":\n",
    "    md(\"Dissolved organic carbon data was compiled from multiple sources\")\n",
    "\n",
    "df_mapping = pd.read_csv(\"../../matched/mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%%R -i df_locs -i variable -i unit -w 500 -h 600\n",
    "library(dplyr, warn.conflicts = FALSE)\n",
    "library(ggplot2, warn.conflicts = FALSE)\n",
    "library(stringr)\n",
    "world_map <- map_data(\"world\")\n",
    "# get lon, lat limits from profile_mld\n",
    "\n",
    "xlim = c(min(df_locs$lon), max(df_locs$lon))\n",
    "ylim = c(min(df_locs$lat), max(df_locs$lat))\n",
    "\n",
    "\n",
    "\n",
    "gg <- df_locs %>%\n",
    "# final six months of the year\n",
    "    ggplot()+\n",
    "    geom_point(aes(lon, lat))+\n",
    "    theme_gray(base_size = 16)+\n",
    "    # add colour scale. Minimum zero, label 100, \">100\"\n",
    "    coord_fixed(xlim = xlim, ylim = ylim, ratio = 1.5) \n",
    "\n",
    "\n",
    "y_labels <-  as.numeric(na.omit(layer_scales(gg)$y$break_positions()))\n",
    "x_labels <- as.numeric(na.omit(layer_scales(gg)$x$break_positions()))\n",
    "x_breaks <- x_labels\n",
    "y_breaks <- y_labels\n",
    "\n",
    "# y labels are north-south coordinates. Make them more appropriate\n",
    "# i.e. 10 should be 10 °N, -10 should be 10 °S\n",
    "\n",
    "y_labels <- ifelse(y_labels >= 0, paste0(y_labels, \"°N\"), paste0(abs(y_labels), \"°S\"))\n",
    "x_labels <- ifelse(x_labels >= 0, paste0(x_labels, \"°E\"), paste0(abs(x_labels), \"°W\"))\n",
    "\n",
    "gg <- gg + scale_x_continuous(breaks = x_breaks, labels = x_labels)+\n",
    "    scale_y_continuous(breaks = y_breaks, labels = y_labels)+\n",
    "    geom_polygon(data = world_map, aes(long, lat, group = group), fill = \"grey60\")\n",
    "\n",
    "# there is no need for x or y axis labels\n",
    "gg <- gg + labs(x = NULL, y = NULL)\n",
    "\n",
    "\n",
    "\n",
    "    # move legen\n",
    "\n",
    "gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"**Figure {chapter}{i_figure}:** Map of PFT observations from Cefas.\")\n",
    "i_figure = i_figure + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "#df\n",
    "# melt columns with model in the name\n",
    "if variable == \"pft\":\n",
    "    melt_columns = [x for x in [\"lon\", \"lat\", \"year\", \"month\", \"day\"] if x in df.columns]\n",
    "    df = (\n",
    "        df\n",
    "        .melt(id_vars = melt_columns, var_name = \"measure\", value_name = \"value\")\n",
    "    \n",
    "    \n",
    "    )\n",
    "df[\"source\"] = [x.split(\"_\")[-1] for x in df.measure]\n",
    "df = (df\n",
    "        .assign(measure = lambda x: x.measure.str.replace(\"_model\", \"\"))\n",
    "        .assign(measure = lambda x: x.measure.str.replace(\"_obs\", \"\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# pivot value using measure\n",
    "pivot_vars = [x for x in [\"lon\", \"lat\", \"year\", \"month\", \"source\"] if x in df.columns]\n",
    "df = (\n",
    "    df.pivot_table(index = pivot_vars, columns = \"measure\", values = \"value\").reset_index()\n",
    "    .reset_index(drop = True)\n",
    "    # drop index name\n",
    "    .rename_axis(None, axis = 1)\n",
    ")\n",
    "# change mod to model and obs  to observation in source\n",
    "df[\"source\"] = df.source.str.replace(\"model\", \"Model\").str.replace(\"obs\", \"Observation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%%R -i df -w 1000 -h 500\n",
    "\n",
    "library(ggtern)\n",
    "library(tidyverse)\n",
    "\n",
    "ggtern(data = df, aes(x = micro_frac, y = pico_frac, z = nano_frac)) +\n",
    "    geom_point()+\n",
    "    theme_rgbw(base_size = 24)+\n",
    "    facet_wrap(~source)+\n",
    "    # add better labels\n",
    "    theme(legend.position = \"bottom\")+\n",
    "    labs( x = \"Micro\", y = \"Pico\", z = \"Nano\")+\n",
    "    percent_custom(\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "i_subplot = 1\n",
    "md(f\"**Figure {chapter}{i_figure}.{i_subplot}**: Ternary plot of the model output for Plankton Functional Types.\")\n",
    "i_subplot += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%%R -i df -w 1000 -h 800\n",
    "\n",
    "library(ggtern)\n",
    "library(tidyverse)\n",
    "\n",
    "ggtern(data = df, aes(x = micro_frac, y = pico_frac, z = nano_frac, colour = source)) +\n",
    "    geom_point()+\n",
    "    theme_rgbw(base_size = 24)+\n",
    "    # add better labels\n",
    "    theme(legend.position = \"bottom\")+\n",
    "    labs( x = \"Micro\", y = \"Pico\", z = \"Nano\")+\n",
    "    # ditch legend labels\n",
    "    theme(legend.title = element_blank())+\n",
    "    percent_custom(\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"**Figure {i_figure}.{i_subplot}**: Ternary plot of the model output for Plankton Functional Types.\")\n",
    "i_subplot += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "## Data Sources\n",
    "\n",
    "Creach and Forster (2017). North Sea phytoplankton pigments 2010 to 2011. Cefas, UK. V1. doi: https://doi.org/10.14466/CefasDataHub.33."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "validation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
