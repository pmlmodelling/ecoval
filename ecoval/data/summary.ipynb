{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# domain_title summary statistics of model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_start\n",
    "shelf = shelf_mask\n",
    "import glob\n",
    "\n",
    "import nctoolkit as nc\n",
    "from mask import mask_all, mask_shelf\n",
    "from ecoval import tidy_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "\n",
    "show_map = False\n",
    "\n",
    "if len([x for x in glob.glob(\"*.ipynb\") if \"summary_shelf\" in x]) > 0:\n",
    "    ds_regions = nc.open_data(f\"{data_dir}/amm7_val_subdomains.nc\")\n",
    "    ds_regions.subset(variables = [\"Shelf\", \"Ocean\"])\n",
    "    ds_regions.sum_all()\n",
    "    ds_regions.as_missing(0)\n",
    "    if shelf:\n",
    "        mask_shelf(ds_regions)\n",
    "    \n",
    "    ds_plot = ds_regions.pub_plot(legend_position=None, land = \"lightgrey\")\n",
    "    show_map = True\n",
    "try:\n",
    "    ensemble = nc.create_ensemble(\"../../results/annual_mean\")\n",
    "    ensemble = tidy_summary_paths(ensemble)\n",
    "except:\n",
    "    ensemble = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if ensemble is not None:\n",
    "    if show_map:\n",
    "        if shelf:\n",
    "            md(f\"**Figure {chapter}{i_figure}**: Map of the shelf area used for the evaluation.\")\n",
    "        else:\n",
    "            md(f\"**Figure {chapter}{i_figure}**: Map of the ocean area used for the evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if ensemble is not None:\n",
    "    md(\"## Taylor diagrams for the sea surface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import nctoolkit as nc\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from IPython.display import display_markdown \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from plotnine import *\n",
    "import numpy as np\n",
    "import os\n",
    "import glob as glob\n",
    "from mask import mask_all, mask_shelf\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "i_table = 1\n",
    "stamp = nc.session_info[\"stamp\"]\n",
    "out = \".trackers/\" + stamp\n",
    "if not os.path.exists(\".trackers\"):\n",
    "    os.makedirs(\".trackers\")\n",
    "# save out as empty file\n",
    "with open(out, 'w') as f:\n",
    "    f.write(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def fix_variable(vv):\n",
    "    if vv.lower() == \"poc\":\n",
    "        return \"POC\"\n",
    "    if vv.lower() == \"doc\":\n",
    "        return \"DOC\"\n",
    "    return vv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "if ensemble is not None:\n",
    "    df_taylor = []\n",
    "    for ff in ensemble:\n",
    "        variable = os.path.basename(ff).split(\"_\")[1].replace(\".nc\", \"\")\n",
    "        ds_ff = nc.open_data(ff)\n",
    "        if True:\n",
    "            mask_shelf(ds_ff)\n",
    "        else:\n",
    "            mask_all(ds_ff)\n",
    "\n",
    "        df_ff = ds_ff.to_dataframe().reset_index()\n",
    "        lon_name = [df_ff.columns[i] for i in range(len(df_ff.columns)) if \"lon\" in df_ff.columns[i]][0]\n",
    "        lat_name = [df_ff.columns[i] for i in range(len(df_ff.columns)) if \"lat\" in df_ff.columns[i]][0]\n",
    "        df_taylor.append(\n",
    "            df_ff\n",
    "            .loc[:,[lon_name, lat_name, \"model\", \"observation\"]]\n",
    "            .dropna()\n",
    "            .assign(variable = variable)\n",
    "        )\n",
    "    df_taylor = pd.concat(df_taylor).reset_index(drop=True)\n",
    "\n",
    "    # fix name of variable\n",
    "    df_taylor = (\n",
    "        df_taylor\n",
    "        .assign(variable = lambda x: x[\"variable\"].apply(tidy_name))\n",
    "    )\n",
    "    # fix variables\n",
    "    df_taylor =(\n",
    "        df_taylor\n",
    "        .assign(variable = lambda x: x[\"variable\"].apply(fix_variable))\n",
    "    )\n",
    "    plot_taylor = True\n",
    "else:\n",
    "    plot_taylor = False\n",
    "    df_taylor = None\n",
    "    df_cor = None\n",
    "    global_grid = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%%R -i df_taylor -w 600 -h 600 -r 120 -i plot_taylor\n",
    "\n",
    "if(plot_taylor){\n",
    "library(plotrix, warn.conflicts = FALSE)\n",
    "library(dplyr, warn.conflicts = FALSE)\n",
    "\n",
    "# get unique variable from df_taylor\n",
    "\n",
    "variables <- df_taylor %>%\n",
    "    group_by(variable) %>%\n",
    "    summarize(nsd = sd(model)/sd(observation))  %>%\n",
    "    arrange(desc(nsd)) %>%\n",
    "    pull(variable) \n",
    "\n",
    "pch = 1:length(variables)\n",
    "col = rainbow(length(variables))\n",
    "\n",
    "r_min <- df_taylor %>%\n",
    "    group_by(variable) %>%\n",
    "    summarise(r = cor(observation, model, use = \"complete.obs\")) %>%\n",
    "    summarize(r = min(r)) %>%\n",
    "    pull(r)\n",
    "\n",
    "pos_cor = r_min >= -0.1\n",
    "\n",
    "i <- 1\n",
    "for (vv in variables){\n",
    "\n",
    "    df_vv <- df_taylor %>%\n",
    "        filter(variable == vv)\n",
    "    if(i == 1){\n",
    "        plot_size <- df_vv %>%\n",
    "        # get the standard deviation of all\n",
    "        summarize(nsd = sd(model)/sd(observation)) %>%\n",
    "        pull(nsd)\n",
    "\n",
    "    }\n",
    "\n",
    "    if (i == 1){\n",
    "        taylor.diagram(df_vv$observation, df_vv$model, pch = pch[i], col = col[i], add = FALSE, normalize = TRUE,\n",
    "        pos.cor = pos_cor, main = NULL\n",
    "\n",
    "        )\n",
    "    } else {\n",
    "        taylor.diagram(df_vv$observation, df_vv$model, pch = pch[i], col = col[i], add = TRUE, normalize = TRUE,\n",
    "        pos.cor = pos_cor\n",
    "\n",
    "        )\n",
    "    }\n",
    "\n",
    "i <- i + 1\n",
    "}\n",
    "\n",
    "legend( plot_size * 1.3, plot_size * 1.9, legend = variables, pch = pch, col = col, bty = \"n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "if plot_taylor:\n",
    "    variables = df_taylor.variable.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if plot_taylor:\n",
    "    md_basic(f\"**Figure {chapter}{i_figure}**: Taylor diagram for **sea surface** annual mean of {', '.join(variables)}. This diagram compares climatological annual averages of the model and observations across the model's spatial domain. Standard devaiation is normalized by the standard deviation of the observations, and a standard deviation below 1 indicates that the model is less variable than the observations. Note: This figure summarizes the overall ability of the model to reproduce climatological **spatial patterns**, and it does not represent temporal performance.\") \n",
    "    i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if plot_taylor:\n",
    "    md(\"## Model biases based on gridded sea surface data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if plot_taylor:\n",
    "    df_bias= []\n",
    "    for ff in ensemble:\n",
    "        variable = os.path.basename(ff).split(\"_\")[1].replace(\".nc\", \"\").title()\n",
    "        if variable.lower() == \"sst\":\n",
    "            variable = \"SST\"\n",
    "        ds_ff = nc.open_data(ff)\n",
    "        ds_ff.set_precision(\"F32\")\n",
    "        if True:\n",
    "            mask_shelf(ds_ff)\n",
    "        else:\n",
    "            mask_all(ds_ff)\n",
    "        ds_ff.assign(bias = lambda x: x.model - x.observation)\n",
    "        ds_ff.spatial_mean()\n",
    "        bias = ds_ff.to_dataframe().reset_index().bias.values[0]\n",
    "        unit = ds_ff.contents.unit[0]\n",
    "        name = variable \n",
    "        model = ds_ff.to_dataframe().reset_index().model.values[0]\n",
    "        observation = ds_ff.to_dataframe().reset_index().observation.values[0]\n",
    "        df_bias.append(pd.DataFrame({\"Variable\": [name], \"Modelled spatial mean\": [model], \"Observational spatial mean\":[observation], \"Model bias\": [bias], \"Unit\": [unit]}))\n",
    "    df_bias = pd.concat(df_bias).reset_index(drop=True)\n",
    "    df_bias = df_bias.assign(percentage_bias = lambda x: x[\"Model bias\"]/x[\"Observational spatial mean\"]*100)\n",
    "    df_bias.loc[df_bias.Variable == \"Temperature\", \"percentage_bias\"] = np.nan\n",
    "    df_bias.columns = [\"Variable\", \"Model mean\", \"Observed mean\", \"Model bias\", \"Unit\", \"Percentage bias\"]\n",
    "    # tidy Variable\n",
    "    df_bias = df_bias.assign(Variable = lambda x: x[\"Variable\"].apply(tidy_name))\n",
    "    # Make everything 2 dp, except for 1st column\n",
    "    df_bias.iloc[:,1:] = df_bias.iloc[:,1:].round(2)\n",
    "    # drop unit\n",
    "    df_bias = df_bias.drop(columns=[\"Unit\"])\n",
    "    df_display(df_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if plot_taylor:\n",
    "    md(f\"**Table {chapter}{i_table}**: Bias of model compared with **sea surface** observations. The bias is calculated as the modelled spatial mean minus the observational spatial mean. The percentage bias is calculated as the model bias divided by the observational spatial mean.\")\n",
    "    i_table += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if plot_taylor:\n",
    "    md(\"## Spatial performance of the model at the sea surface\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if plot_taylor:\n",
    "    df_cor = []\n",
    "    for ff in ensemble:\n",
    "        variable = os.path.basename(ff).split(\"_\")[1].replace(\".nc\", \"\").title()\n",
    "        if variable.lower() == \"sst\":\n",
    "            variable = \"SST\"\n",
    "        ds_ff = nc.open_data(ff)\n",
    "        ds_ff.set_precision(\"F32\")\n",
    "        if True:\n",
    "            mask_shelf(ds_ff)\n",
    "        else:\n",
    "            mask_all(ds_ff)\n",
    "        ds_ff.cor_space(\"model\", \"observation\")\n",
    "        ff_cor = (\n",
    "            ds_ff\n",
    "            .to_dataframe()\n",
    "            .dropna()\n",
    "            .cor\n",
    "            .values\n",
    "            [0]\n",
    "        )\n",
    "        df_cor.append(pd.DataFrame({\"Variable\": [variable], \"Correlation\": [ff_cor]}))\n",
    "    df_cor = pd.concat(df_cor).reset_index(drop=True)\n",
    "    df_cor.columns = [\"Variable\", \"Spatial correlation between model and observations\"]\n",
    "    # tidy Variable\n",
    "    df_cor = df_cor.assign(Variable = lambda x: x[\"Variable\"].apply(tidy_name))\n",
    "    df_display(df_cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if plot_taylor:\n",
    "    md(f\"**Table {chapter}{i_table}**: Pearson correlation coefficient between model and observations at the **sea surface** for annual mean of {tidy_name(variables, lower = True)}. This table compares climatological annual averages of the model and observations across the model's spatial domain. Standard devaiation is normalized by the standard deviation of the observations, and a standard deviation below 1 indicates that the model is less variable than the observations.\") \n",
    "    i_table += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if plot_taylor:\n",
    "    md(\"## Temporal performance of the model at the sea surface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "if plot_taylor:\n",
    "    global_grid = False\n",
    "    paths =   glob.glob(\"../../results/temporals/*.nc\")\n",
    "    paths = tidy_summary_paths(paths)\n",
    "    for ff in paths:\n",
    "        ds_ff = nc.open_data(ff)\n",
    "        df_ff = ds_ff.to_dataframe().reset_index()\n",
    "        lat_name = [df_ff.columns[i] for i in range(len(df_ff.columns)) if \"lat\" in df_ff.columns[i]][0]\n",
    "        lat_min = df_ff[lat_name].values.min()\n",
    "        lat_max = df_ff[lat_name].values.max()\n",
    "        if lat_min < -89 and lat_max > 89:\n",
    "            global_grid = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "if plot_taylor:\n",
    "    df_cor = []\n",
    "    paths =  glob.glob(\"../../results/temporals/*.nc\")\n",
    "    paths = tidy_summary_paths(paths)\n",
    "    for ff in paths:\n",
    "        ds_ff = nc.open_data(ff)\n",
    "        if global_grid:\n",
    "            ds_ff.to_latlon(lon = [-179.5, 179.5], lat = [-89.5, 89.5], res = 1)\n",
    "        if True:\n",
    "            mask_shelf(ds_ff)\n",
    "        else:\n",
    "            mask_all(ds_ff)\n",
    "        df_ff = ds_ff.to_dataframe().reset_index().dropna()\n",
    "        lon_name = [df_ff.columns[i] for i in range(len(df_ff.columns)) if \"lon\" in df_ff.columns[i]][0]\n",
    "        lat_name = [df_ff.columns[i] for i in range(len(df_ff.columns)) if \"lat\" in df_ff.columns[i]][0]\n",
    "        # rename them\n",
    "        df_ff = df_ff.assign(lon = df_ff[lon_name], lat = df_ff[lat_name])\n",
    "        variable = os.path.basename(ff).split(\"_\")[0].replace(\".nc\", \"\").title()\n",
    "        if variable.lower() == \"sst\":\n",
    "            variable = \"SST\"\n",
    "        df_ff = df_ff.assign(variable = variable)\n",
    "        df_cor.append(df_ff)\n",
    "    # tidy variable name\n",
    "    \n",
    "    \n",
    "    df_cor = pd.concat(df_cor).reset_index(drop=True)\n",
    "    df_cor = df_cor.assign(variable = lambda x: x[\"variable\"].apply(tidy_name))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%%R -i df_cor -i global_grid -i plot_taylor -r 120\n",
    "if(plot_taylor){\n",
    "library(ggplot2, warn.conflicts = FALSE)\n",
    "library(tidyverse, warn.conflicts = FALSE)\n",
    "world_map <- map_data(\"world\")\n",
    "\n",
    "xlim <- c(min(df_cor$lon), max(df_cor$lon))\n",
    "ylim <- c(min(df_cor$lat), max(df_cor$lat))\n",
    "\n",
    "min_val <- min(df_cor$cor)\n",
    "max_val <- max(df_cor$cor)\n",
    "# CO2, superscript in markdown\n",
    "df_cor <- df_cor %>%\n",
    "        mutate(variable = gsub(\"CO2\", \"CO<sub>2</sub>\", variable)) \n",
    "df_cor <- df_cor %>%\n",
    "        mutate(variable = gsub(\"co2\", \"CO<sub>2</sub>\", variable)) \n",
    "df_cor <- df_cor %>%\n",
    "        mutate(variable = gsub(\"CO_2\", \"CO<sub>2</sub>\", variable)) \n",
    "\n",
    "\n",
    "gg <- ggplot(df_cor)+\n",
    "        geom_raster(aes(x  = lon,y =   lat, fill = cor))+ \n",
    "        coord_cartesian(xlim = xlim, ylim = ylim)+\n",
    "        theme_bw(base_size = 12)+\n",
    "        facet_wrap(~variable)+\n",
    "        labs(fill = \"Correlation coefficient\")+\n",
    "        theme_bw(base_family = \"Helvetica\", base_size = 8) +\n",
    "        theme(\n",
    "          legend.position = \"bottom\", legend.direction = \"horizontal\", legend.box = \"horizontal\", legend.key.width = unit(3.0, \"cm\"),\n",
    "          legend.key.height = unit(0.5, \"cm\")\n",
    "        ) +\n",
    "        labs(x = NULL, y = NULL) +\n",
    "        theme(plot.margin = unit(c(2, 0, 2, 0), \"mm\")) +\n",
    "        theme(plot.title = element_text(hjust = 0.5))+\n",
    "        theme(strip.text = ggtext::element_markdown())\n",
    "        # use element_markdown for facet labels\n",
    "\n",
    "        # make the legend 3 cm wide\n",
    "        # theme( legend_key_size = unit(3, \"cm\"))\n",
    "\n",
    "\n",
    "\n",
    "if (min_val < 0 & max_val > 0){\n",
    "        gg <- gg + \n",
    "                scale_fill_gradient2(low = \"blue\", high = \"red\", mid = \"white\", midpoint = 0, \n",
    "                guide = guide_colorbar(title.position = \"bottom\", title.hjust = 0.5, title.theme = element_text(angle = 0, size = 10, family = \"Helvetica\")),\n",
    "                breaks = seq(-1, 1, 0.25))\n",
    "}\n",
    "if (min_val > 0){\n",
    "        gg <- gg + \n",
    "                scale_fill_viridis_c(\n",
    "                guide = guide_colorbar(title.position = \"bottom\", title.hjust = 0.5, title.theme = element_text(angle = 0, size = 10, family = \"Helvetica\"))\n",
    "                )\n",
    "}\n",
    "\n",
    "\n",
    "y_labels <-  as.numeric(na.omit(layer_scales(gg)$y$break_positions()))\n",
    "x_labels <- as.numeric(na.omit(layer_scales(gg)$x$break_positions()))\n",
    "x_breaks <- x_labels\n",
    "y_breaks <- y_labels\n",
    "\n",
    "# y labels are north-south coordinates. Make them more appropriate\n",
    "# i.e. 10 should be 10 °N, -10 should be 10 °S\n",
    "\n",
    "y_labels <- ifelse(y_labels >= 0, paste0(y_labels, \"°N\"), paste0(abs(y_labels), \"°S\"))\n",
    "x_labels <- ifelse(x_labels >= 0, paste0(x_labels, \"°E\"), paste0(abs(x_labels), \"°W\"))\n",
    "\n",
    "gg <- gg + scale_y_continuous(breaks = y_breaks, labels = y_labels) +\n",
    "          scale_x_continuous(breaks = x_breaks, labels = x_labels)+\n",
    "          geom_polygon(data = world_map, aes(x = long, y = lat, group = group), fill = \"grey\", colour = \"grey\")\n",
    "gg\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if plot_taylor:\n",
    "    md(f\"**Figure {chapter}{i_figure}**: Spatial correlation (Pearson correlation coefficient) between model and observations for annual mean of {tidy_name(variables, lower = True)}. This figure compares climatological monthly averages of the model and observations across the model's spatial domain.\")\n",
    "    i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if plot_taylor:\n",
    "    md(\"The overall ability of the model reproduce the seasonality of each variable was estimated by calculating the spatial mean of the Pearson correlation coefficient between the model and the observations. The spatial mean was calculated by averaging the correlation coefficient of each grid cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "if plot_taylor:\n",
    "    df_cor = []\n",
    "    paths = glob.glob(\"../../results/temporals/*.nc\")\n",
    "    paths = tidy_summary_paths(paths)\n",
    "    for ff in paths:\n",
    "        ds_ff = nc.open_data(ff, checks = False)\n",
    "        ds_ff.spatial_mean()\n",
    "        variable = os.path.basename(ff).split(\"_\")[0].replace(\".nc\", \"\").title()\n",
    "        if variable.lower() == \"sst\":\n",
    "            variable = \"SST\"\n",
    "        df_cor.append(pd.DataFrame({\"Variable\": [variable], \"Correlation\": [ds_ff.to_dataframe().reset_index().cor.values[0]]}))\n",
    "    \n",
    "    df_cor = pd.concat(df_cor).reset_index(drop=True)\n",
    "    \n",
    "    # tidy Variable\n",
    "    df_cor = df_cor.assign(Variable = lambda x: x[\"Variable\"].apply(tidy_name))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Make everything 2 dp, except for 1st column\n",
    "if plot_taylor:\n",
    "    df_display(df_cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if plot_taylor:\n",
    "    md(f\"**Table {chapter}{i_table}**: Spatial average of the temporal correlation (Pearson correlation coefficient) between model and observations for annual mean of {tidy_name(variables, lower = True)}. The correlation is calculated for each grid cell individually using monthly climatological averages. The spatial average is then calculated for each variable.\")\n",
    "    i_table += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "paths = glob.glob(\"../../results/**_depth_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if len(paths) > 0:\n",
    "    md(\"## Perfomance of model across depths\")\n",
    "    md(\"Root mean square deviation (RMSD), bias and correlation between model and observations were calculated for each variable at different depths. The RMSD is calculated as the square root of the mean of the squared differences between the model and observations. The bias is calculated as the modelled spatial mean minus the observational spatial mean. The correlation is calculated for each variable at different depths.\") \n",
    "    def bin_depth(x):\n",
    "        if x <= 10:\n",
    "            return \"0-10m\"\n",
    "        if x <= 30:\n",
    "            return \"10-30m\"\n",
    "        if x <= 60:\n",
    "            return \"30-60m\"\n",
    "        if x <= 100:\n",
    "            return \"60-100m\"\n",
    "        if x <= 150:\n",
    "            return \"100-150m\"\n",
    "        if x <= 300:\n",
    "            return \"150-300m\"\n",
    "        if x <= 600:\n",
    "            return \"300-600m\"\n",
    "        if x <= 1000:\n",
    "          return \"600-1000m\"\n",
    "        return np.nan \n",
    "    df_map = []\n",
    "    for ff in paths:\n",
    "        vv = os.path.basename(ff).split(\"_\")[0]\n",
    "        ff_points = glob.glob(f\"../../matched/point/nws/all/{vv}/*all*{vv}.csv\")[0]\n",
    "        vv = vv.title()\n",
    "        df_ff = pd.read_csv(ff_points).loc[:,[\"lon\", \"lat\", \"depth\"]]\n",
    "        lon_min = lon_lim[0]\n",
    "        lon_max = lon_lim[1]\n",
    "        lat_min = lat_lim[0]\n",
    "        lat_max = lat_lim[1]\n",
    "        # filter by lon and lat\n",
    "        df_ff = df_ff.query(f\"lon >= {lon_min} and lon <= {lon_max} and lat >= {lat_min} and lat <= {lat_max}\").reset_index(drop = True)\n",
    "        df_ff = df_ff.assign(depth_bin = df_ff[\"depth\"].apply(bin_depth))\n",
    "        # add variable\n",
    "        df_ff = df_ff.assign(variable = vv)\n",
    "        df_map.append(df_ff)\n",
    "    df_map = pd.concat(df_map).reset_index(drop=True)\n",
    "    # drop na\n",
    "    df_map = df_map.dropna()\n",
    "    plot_map = True\n",
    "else:\n",
    "    df_map = None\n",
    "    plot_map = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%%R -i df_map -i plot_map -w 600 -h 600\n",
    "if(plot_map){\n",
    "library(ggplot2, warn.conflicts = FALSE)\n",
    "library(tidyverse)\n",
    "world_map <- map_data(\"world\")\n",
    "\n",
    "xlim <- c(min(df_map$lon), max(df_map$lon))\n",
    "ylim <- c(min(df_map$lat), max(df_map$lat))\n",
    "#    mutate(depth = factor(depth, levels = c(\"0-10m\", \"10-30m\", \"30-60m\", \"60-100m\", \"100-150m\", \"150-300m\", \"300-600m\", \"600-1000m\", \">1000m\")))\n",
    "df_map <- df_map %>%\n",
    "    mutate(depth_bin = factor(depth_bin, levels = c(\"0-10m\", \"10-30m\", \"30-60m\", \"60-100m\", \"100-150m\", \"150-300m\", \"300-600m\", \"600-1000m\")))\n",
    "\n",
    "\n",
    "gg <- ggplot(df_map)+\n",
    "        geom_point(aes(x  = lon,y =   lat), size = 0.5)+ \n",
    "        coord_cartesian(xlim = xlim, ylim = ylim)+\n",
    "        theme_bw(base_size = 24)+\n",
    "        facet_grid(variable~depth_bin)+\n",
    "        labs(color = \"Depth bin\")+\n",
    "        theme_bw(base_family = \"Helvetica\", base_size = 8) +\n",
    "        theme(\n",
    "          legend.position = \"bottom\", legend.direction = \"horizontal\", legend.box = \"horizontal\", legend.key.width = unit(3.0, \"cm\"),\n",
    "          legend.key.height = unit(0.5, \"cm\")\n",
    "        ) +\n",
    "        labs(x = NULL, y = NULL) +\n",
    "        theme(plot.margin = unit(c(2, 0, 2, 0), \"mm\")) +\n",
    "        theme(plot.title = element_text(hjust = 0.5))\n",
    "        # make the legend 3 cm wide\n",
    "        # theme( legend_key_size = unit(3, \"cm\"))\n",
    "\n",
    "y_labels <-  as.numeric(na.omit(layer_scales(gg)$y$break_positions()))\n",
    "x_labels <- as.numeric(na.omit(layer_scales(gg)$x$break_positions()))\n",
    "x_breaks <- x_labels\n",
    "y_breaks <- y_labels\n",
    "\n",
    "# y labels are north-south coordinates. Make them more appropriate\n",
    "# i.e. 10 should be 10 °N, -10 should be 10 °S\n",
    "\n",
    "y_labels <- ifelse(y_labels >= 0, paste0(y_labels, \"°N\"), paste0(abs(y_labels), \"°S\"))\n",
    "x_labels <- ifelse(x_labels >= 0, paste0(x_labels, \"°E\"), paste0(abs(x_labels), \"°W\"))\n",
    "\n",
    "gg <- gg + scale_y_continuous(breaks = y_breaks, labels = y_labels) +\n",
    "          scale_x_continuous(breaks = x_breaks, labels = x_labels)+\n",
    "          geom_polygon(data = world_map, aes(x = long, y = lat, group = group), fill = \"grey\", colour = \"grey\")\n",
    "gg\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if plot_map:\n",
    "    md(f\"**Figure {chapter}{i_figure}**: Map of the locations of matchups at each depth range.\") \n",
    "    i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if len(paths) > 0:\n",
    "\n",
    "    df_depth = []\n",
    "    for ff in paths:\n",
    "        df = pd.read_csv(ff)\n",
    "        vv_ff = os.path.basename(ff).split(\"_\")[0]\n",
    "        df_depth.append(\n",
    "            df\n",
    "            .loc[:,[\"Depth\", \"RMSD\", \"unit\"]]\n",
    "            # spread RMSD using Depth\n",
    "            .pivot(index = \"unit\", columns = \"Depth\", values = \"RMSD\")\n",
    "            .assign(variable = vv_ff)\n",
    "            # put variable column first\n",
    "            .reset_index()\n",
    "            .set_index(\"variable\")\n",
    "            .reset_index()\n",
    "\n",
    "        )\n",
    "    df_depth = pd.concat(df_depth).reset_index(drop=True)\n",
    "#        mutate(depth_bin = factor(depth_bin, levels = c(\"0-10m\", \"10-30m\", \"30-60m\", \"60-100m\", \"100-150m\", \"150-300m\", \"300-600m\", \"600-1000m\")))\n",
    "    # Change the order of the columns\n",
    "    locs = [ x for x in [\"variable\", \"unit\", \"0-10m\", \"10-30m\", \"30-60m\", \"60-100m\", \"100-150m\", \"150-300m\", \"300-600m\", \"600-1000m\", \">1000m\", \"0-150m\"] if x in df_depth.columns]\n",
    "    df_depth = df_depth.loc[:,locs]\n",
    "\n",
    "    df_display(df_depth)\n",
    "    md(f\"**Table {chapter}{i_table}**: Root mean square deviation (RMSD) of model compared with observations at different depths. The RMSD is calculated as the square root of the mean of the squared differences between the model and observations.\")\n",
    "    i_table += 1\n",
    "\n",
    "    # now do bias\n",
    "    df_bias = []\n",
    "    for ff in paths:\n",
    "        df = pd.read_csv(ff)\n",
    "        vv_ff = os.path.basename(ff).split(\"_\")[0]\n",
    "        df_bias.append(\n",
    "            df\n",
    "            .loc[:,[\"Depth\", \"Bias\", \"unit\"]]\n",
    "            # spread RMSD using Depth\n",
    "            .pivot(index = \"unit\", columns = \"Depth\", values = \"Bias\")\n",
    "            .assign(variable = vv_ff)\n",
    "            # put variable column first\n",
    "            .reset_index()\n",
    "            .set_index(\"variable\")\n",
    "            .reset_index()\n",
    "\n",
    "        )\n",
    "    df_bias = pd.concat(df_bias).reset_index(drop=True)\n",
    "    locs = [x for x in [\"variable\", \"unit\", \"0-10m\", \"10-30m\", \"30-60m\", \"60-100m\", \"100-150m\", \"150-300m\", \"300-600m\", \"600-1000m\", \">1000m\", \"0-150m\"] if x in df_bias.columns]\n",
    "    df_bias = df_bias.loc[:,locs]\n",
    "    df_display(df_bias)\n",
    "    md(f\"**Table {chapter}{i_table}**: Bias of model compared with observations at different depths.\")\n",
    "\n",
    "    i_table += 1\n",
    "\n",
    "    # now do correlation\n",
    "\n",
    "    df_cor = []\n",
    "    for ff in paths:\n",
    "        df = pd.read_csv(ff)\n",
    "        vv_ff = os.path.basename(ff).split(\"_\")[0]\n",
    "        df_cor.append(\n",
    "            df\n",
    "            .loc[:,[\"Depth\", \"Correlation\"]]\n",
    "            # spread RMSD using Depth\n",
    "             .assign(variable = vv_ff)\n",
    "            .pivot(index = \"variable\", columns = \"Depth\", values = \"Correlation\")\n",
    "            # put variable column first\n",
    "            .reset_index()\n",
    "            # .set_index(\"variable\")\n",
    "        )\n",
    "    df_cor = pd.concat(df_cor).reset_index(drop=True)\n",
    "    locs = [x for x in [\"variable\", \"0-10m\", \"10-30m\", \"30-60m\", \"60-100m\", \"100-150m\", \"150-300m\", \"300-600m\", \"600-1000m\", \">1000m\", \"0-150m\"] if x in df_cor.columns]\n",
    "    df_cor = df_cor.loc[:,locs]\n",
    "    df_display(df_cor)\n",
    "    md(f\"**Table {chapter}{i_table}**: Pearson correlation coefficient between model and observations at different depths. The correlation is calculated for each variable at different depths.\")\n",
    "    i_table += 1\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecoval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
