{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64f4a51d",
   "metadata": {},
   "source": [
    "# How biased are the simulations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224944b6",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe6c2b7",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# model_dict = {\n",
    "#     \"LOCATE\":\"/data/proteus1/scratch/gle/getmval/locate\",\n",
    "#     \"GETM\":\"/data/proteus1/scratch/rwi/adhoc/getm/3dmn\"\n",
    "# }\n",
    "\n",
    "model_dict = model_dict_str\n",
    "num_models = len(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c445cc99",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "annual_paths = []\n",
    "for key in model_dict:\n",
    "    if not os.path.exists(model_dict[key] + \"/results/annual_mean/\"):\n",
    "        raise ValueError(\"No annual mean folder found for \" + key)\n",
    "    paths = glob.glob(model_dict[key] + \"/results/annual_mean/*\")\n",
    "    paths = tidy_summary_paths(paths)\n",
    "    annual_paths.append(\n",
    "        pd.DataFrame({\"path\": paths})\n",
    "        .assign(model = key)\n",
    "    )\n",
    "\n",
    "\n",
    "annual_paths = pd.concat(annual_paths)\n",
    "\n",
    "annual_paths[\"base_name\"] = annual_paths[\"path\"].apply(lambda x: os.path.basename(x))\n",
    "# only interested in netcdf file in path\n",
    "annual_paths = annual_paths[annual_paths[\"base_name\"].str.contains(\".nc\")]\n",
    "# fix base_name using fix_base_name\n",
    "annual_paths[\"base_name\"] = annual_paths[\"base_name\"].apply(fix_basename)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5295b3c1",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "annual_paths = (\n",
    "    annual_paths\n",
    "    .groupby(\"base_name\")\n",
    "    .count()\n",
    "      .query(\"model > 1\")\n",
    "      .reset_index()\n",
    "      .drop(columns = [\"path\", \"model\"])\n",
    "      .merge(annual_paths)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b61904",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "base_names = annual_paths.base_name.unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf964f4a",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "output = dict()\n",
    "md_output = dict()\n",
    "text_output = dict()\n",
    "# list to track data frames with correlation coefficients\n",
    "df_cor = []\n",
    "df_abs = []\n",
    "for bb in base_names:\n",
    "    variable = bb.split(\"_\")[1].replace(\".nc\", \"\")\n",
    "    bb_paths = annual_paths.query(\"base_name == @bb\").reset_index(drop = True)\n",
    "    n_cols = len(bb_paths)\n",
    "    # generate the mask first\n",
    "\n",
    "    ds_mask = nc.open_data(bb_paths.path[0])\n",
    "    ds_mask.run()\n",
    "    for ff in bb_paths.path[1:]:\n",
    "        ds_ff = nc.open_data(ff)\n",
    "        ds_ff.regrid(ds_mask)\n",
    "        ds_mask * ds_ff\n",
    "        ds_mask.run()\n",
    "        ds_mask.abs()\n",
    "        ds_mask > 0\n",
    "        ds_mask.run()\n",
    "    df_mask = (\n",
    "        ds_mask.to_dataframe()\n",
    "        .dropna()\n",
    "        .reset_index()\n",
    "    )\n",
    "    lon_name = [x for x in df_mask.columns if \"lon\" in x][0]\n",
    "    lat_name = [x for x in df_mask.columns if \"lat\" in x][0]\n",
    "    # rename \n",
    "    df_mask = df_mask.rename(columns = {lon_name: \"lon\", lat_name: \"lat\"})\n",
    "\n",
    "    lon_min = df_mask.lon.min()\n",
    "    lon_max = df_mask.lon.max()\n",
    "    lat_min = df_mask.lat.min()\n",
    "    lat_max = df_mask.lat.max()\n",
    "    lons = [lon_min, lon_max]\n",
    "    lats = [lat_min, lat_max]\n",
    "    # coerse to float\n",
    "    lons = [float(x) for x in lons]\n",
    "    lats = [float(x) for x in lats]\n",
    "    ds_mask.subset(lon = lons, lat = lats)\n",
    "    ds_mask.run()\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.subplots_adjust(wspace=20, hspace=20)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "    # Create 4x4 Grid\n",
    "    \n",
    "    key = md(f\"## How biased is surface {fix_variable_name(variable)}?\")\n",
    "\n",
    "    gs = fig.add_gridspec(nrows=1, ncols=num_models + 1, wspace = 0.6, hspace = 0)\n",
    "    # get the minimum and maximum values for the colorbar\n",
    "\n",
    "    z_max = -1\n",
    "    z_min = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(0, len(bb_paths)):\n",
    "        ds = nc.open_data(bb_paths.path[i])\n",
    "        ds.regrid(ds_mask, \"nn\")\n",
    "        ds * ds_mask\n",
    "        ds.assign(bias = lambda x: x.model - x.observation)\n",
    "        ds.run()\n",
    "        i_max = ds.to_dataframe().dropna().reset_index().bias.quantile(0.98)\n",
    "        i_min = ds.to_dataframe().dropna().reset_index().bias.quantile(0.02)\n",
    "        if i_max > z_max:\n",
    "            z_max = i_max\n",
    "        if i_min < z_min:\n",
    "            z_min = i_min\n",
    "\n",
    "\n",
    "    for i in range(0, len(bb_paths)):\n",
    "        ds = nc.open_data(bb_paths.path[i])\n",
    "        unit  = ds.contents.unit[0]\n",
    "        ds.regrid(ds_mask, \"nn\")\n",
    "        ds * ds_mask\n",
    "        ds.run()\n",
    "        ds.assign(bias = lambda x: x.model - x.observation, drop = True)\n",
    "        ds.set_longnames({\"bias\": \"Bias\"})\n",
    "        ds.set_units({\"bias\": unit})\n",
    "        #get the model run name\n",
    "        model_name = bb_paths.model[i]\n",
    "        ds.to_latlon(lon = lons, lat = lats, res = [0.111, 0.067])\n",
    "        ds.pub_plot(  fig = fig, gs = gs[0,i], title = model_name, limits = [z_min, z_max])\n",
    "        ds_abs = ds.copy()\n",
    "        ds.spatial_mean()\n",
    "        cor_value = ds.to_dataframe().dropna().reset_index().bias[0]\n",
    "        # stick this in a dataframme\n",
    "        df_cor.append(\n",
    "            pd.DataFrame({\"model\": [model_name], \"variable\": variable, \"bias\": cor_value})\n",
    "        )\n",
    "        ds_abs.abs()\n",
    "        ds_abs.run()\n",
    "        ds_abs.spatial_mean()\n",
    "        # calculate the normalized bias\n",
    "        ds = nc.open_data(bb_paths.path[i])\n",
    "        ds.to_latlon(lon = lons, lat = lats, res = [0.111, 0.067]) \n",
    "        ds.assign(bias = lambda x: x.model - x.observation)\n",
    "        ds.drop(variable = \"model\")\n",
    "        ds.cell_area(join = True)\n",
    "        ds.assign(bias = lambda x: x.bias * x.cell_area)\n",
    "        ds.assign(observation = lambda x: x.observation * x.cell_area)\n",
    "        ds.spatial_sum()\n",
    "        ds.assign(bias = lambda x: x.bias / x.observation, drop = True)\n",
    "        norm_bias = ds.to_dataframe().dropna().reset_index().bias[0]\n",
    "        df_abs.append(\n",
    "            pd.DataFrame({\"model\": [model_name], \"variable\": variable, \"bias\": ds_abs.to_dataframe().dropna().reset_index().bias[0]})\n",
    "            .assign(unit = unit)\n",
    "            .assign(norm_bias = norm_bias)\n",
    "        )\n",
    "\n",
    "\n",
    "    output[key] = fig \n",
    "\n",
    "    ds_diff = nc.open_data(bb_paths.path[0])\n",
    "    ds_diff.subset(variable = \"model\")\n",
    "    ds1 = nc.open_data(bb_paths.path[1])\n",
    "    ds1.subset(variable = \"model\")\n",
    "    ds1.regrid(ds_diff)\n",
    "    ds_diff - ds1\n",
    "    ds_diff.regrid(ds_mask, \"nn\")\n",
    "    ds_mask.subset(variable = \"model\")\n",
    "    ds_diff * ds_mask\n",
    "    ds_diff.run()\n",
    "    model1 = bb_paths.model[0]\n",
    "    model2 = bb_paths.model[1]\n",
    "    title = f\"{model1} - {model2}\"\n",
    "    ds_diff.set_longnames({ds_diff.variables[0]: title})\n",
    "    ds_diff.to_latlon(lon = lons, lat = lats, res = [0.111, 0.067]) \n",
    "    ds_diff.pub_plot(  fig = fig, gs = gs[0,2], title = title, limits = [\"2%\", \"98%\"])\n",
    "\n",
    "\n",
    "    md_output[key] = md(f\"**Figure {i_figure}**: Model bias for surface {fix_variable_name(variable)}. The first two columns show **model - observation** for the two simulations. The third column shows the difference between the two models.\")\n",
    "    i_figure += 1\n",
    "    try:\n",
    "        name1 = bb_paths.base_name[0].split(variable)[1].split(\"_\")[1].replace(\".nc\", \"\")\n",
    "        name2 = bb_paths.base_name[1].split(variable)[1].split(\"_\")[1].replace(\".nc\", \"\")\n",
    "    except:\n",
    "        name1 = \"foo\"\n",
    "        name2 = \"bar\"\n",
    "    comp_text = None\n",
    "    if name1 == name2:\n",
    "        if len(name1) > 0:\n",
    "            source = name1.upper()\n",
    "            comp_text = f\"Bias was calculated by comparing annual averages in the simulation with the observational data from **{source}**.\"\n",
    "    text_output[key] = comp_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d797100d",
   "metadata": {
    "tags": [
     "remove-input",
     "hide-code"
    ]
   },
   "outputs": [],
   "source": [
    "for key in output:\n",
    "    key\n",
    "    if text_output[key] is not None:\n",
    "        display(md(text_output[key]))\n",
    "    display(output[key])\n",
    "    display(md_output[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b406c18",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "df_cor = pd.concat(df_cor)\n",
    "df_abs = pd.concat(df_abs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbfe54b",
   "metadata": {},
   "source": [
    "## Overall summary of model biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe29ab01",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# spread model and cor in columns\n",
    "# df_cor.pivot(index = \"variable\", columns = \"model\", values = \"bias\")\n",
    "\n",
    "df_out = (\n",
    "    df_cor.pivot(index = \"variable\", columns = \"model\", values = \"bias\")\n",
    "    .reset_index()\n",
    "    .merge(\n",
    "    df_abs\n",
    "    .loc[:,[\"variable\", \"unit\"]]\n",
    "    .drop_duplicates()\n",
    ")\n",
    ")\n",
    "df_display(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bcba10",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"**Table {i_table}**: Mean bias for each model and variable\") \n",
    "i_table += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2357b095",
   "metadata": {},
   "source": [
    "To make biases more comparable, the table below summarizes the normalized biases of each simulation, using the equation:\n",
    "\n",
    "$$\n",
    "\\text{Normalized bias} = \\frac{\\sum_{i=1}^{n} \\left| M_i - O_i \\right|}{\\sum_{i=1}^{n} O_i}\n",
    "\n",
    "$$\n",
    "\n",
    "where $M_i$ is the model output, $O_i$ is the observed value, and $n$ is the number of data points. The normalized bias is a measure of how much the model output deviates from the observed value, relative to the observed value. A normalized bias of 0 means that the model output is exactly the same as the observed value, while a normalized bias of 1 means that the model output is twice as large as the observed value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9038ca5",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "df_out = df_abs.pivot(index = \"variable\", columns = \"model\", values = \"norm_bias\").reset_index()\n",
    "df_display(df_out)\n",
    "md(f\"**Table {i_table}**: Normalized bias for each model and variable\")\n",
    "i_table += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7b3711",
   "metadata": {},
   "source": [
    "The table below shows mean absolute error for each model and variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb89eef",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "df_out = df_abs.pivot(index = \"variable\", columns = \"model\", values = \"bias\").reset_index()\n",
    "# display the table without index\n",
    "df_display(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8a7105",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"**Table {i_table}**: Mean absolute error for each model and variable\")\n",
    "i_table += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
